%!TEX root = ../main.tex

\section{Challenges and Opportunities}
\label{sec: challenge}

It brings new research challenges and opportunities to design an AI-native database, which aims to support data management, data analysis, machine learning together in the same system.

\subsection{From one-size-doesn't-fit-all to one-stack-fits-all}

Michael Stonebraker argues that one size does not fit all, due to various applications (e.g., OLTP, OLAP, stream, graph) and diversified hardware (e.g., CPU, ARM, GPU, FPGA, NVM). Note that the database components and their variants are limited, but the number of possible combinations for these components to assemble a database is huge. So the database architects design the database architectures by combining different variants of techniques based on their empirical rules and experience. Thus these human-designed databases may not be optimal because they may fall into a local optimum. It calls for automatically designing a database using AI techniques, which can adapt to different scenarios. 


We argue that one stack fits all. The basic idea is to first implement the database components, e.g., indexes, optimizers, storage, where each component has multiple variants/options, then use AI techniques to assemble these components to form some database candidates, and finally select a database that best suits a given scenario. In this way, we can automatically verify different possible databases (i.e., different combinations of components), explore many more possible database designs than human-based deign, and could design more powerful databases. This is similar to AlphaGO, where the learning-based method beats humans, because the machines can explore more unknown spaces. 


There are several challenges in one-stack-fits-all. First, each component should provide standard interfaces such that different components can be integrated together. Second, each component should have different variants or implementations, e.g., different indexes, different optimizers. Third, it calls for a learning-based component to assemble different components. Fourth, the assembled database can be evaluated and verified before the database is deployed in real applications.  Fifth, each component should be run on different hardware, e.g., learned optimizers should be run on AI chips and traditional cost-based optimizers should be run on general-purpose chips. It calls for effective methods to schedule the tasks. 


\subsection{Next Generation Analytic Processing: OLAP 2.0}

Traditional OLAP focuses on relational data analytics. However, in the big data era, many new data types have emerged, e.g., graph data, time-series data, spatial data, it calls for new data analytics techniques to analyze these multi-model data. Moreover, besides traditional aggregation queries, many applications require to use machine learning algorithms to enhance data analytics, e.g., image analysis. Thus it is rather  challenging to integrate AI and DB techniques to provide new data analytics functionality. We think that hybrid DB and AI online analytic processing on multi-model data should be the next generation OLAP, i.e., {\it OLAP 2.0}. 

There are several challenges in supporting OLAP 2.0. First, different data types use different models, e.g., relational model, graph model, KV model, tensor model, and it calls for a new model to support multi-model data analytics. Second, OLAP 2.0 queries may involve both database operations and AI operations, and it needs to design new optimization model to optimize these heterogeneous operations across different hardware. 



\subsection{Next Generation Transaction Processing: OLTP 2.0}

Traditional OLTP mainly uses general-purpose hardware, e.g., CPU, RAM and Disk, but cannot make full use of new hardware, e.g., AI chips, RDMA, and NVM. Actually, we can utilize new hardware to improve transaction processing. First, based on the characteristics of NVM, including non-volatile, read-write asymmetry speed, and wear-leveling, we need to reconsider the database architecture. For example, we can utilize NVM to replace RAM and replace page-level storage with record-level storage on NVM. Second, we can utilize RDMA to improve the data transmission in databases. Moreover, we can use the programmable feature of intelligent Ethernet card to enable filtering on RDMA and avoid unnecessary processing in RAM and CPU. Third, there are some AI chips which are specially designed hardware, and it is also promising to design database-oriented chips that are specially defined hardware for databases. 


There are several challenges in supporting OLTP 2.0. First, it is challenging to fully utilize new hardware to design a new generation database. Second, it is hard to evaluate and verify whether the new hardware can benefit the database architecture. Third, it calls for an effective tool to automatically evaluate a feature or a component (even a database). 




% Fifth, each component should be run on different hardware, e.g., learned optimizers should be run on AI chips and traditional optimizers should be run 




\subsection{AI4DB}

There are several challenges that embed AI capabilities in databases. 

\hi{Training Samples.} Most AI models require large-scale, high-quality, diversified training data to achieve good performance. However, it is rather hard to get training data in databases, because the data either is security critical or relies on DBAs. For example, in database knob tuning, the training samples should be gotten based on DBAs' experiences. Thus it is hard to get a large number of training samples. Moreover, the training data should cover different scenarios, different hardware environments, and different workloads.  

% Moreover, the training data must be high quality, number and diversity of samples.

\hi{Model Selection.} There are lots of machine learning algorithms and it is hard to automatically select an appropriate algorithm for different scenarios. Moreover, the model selection is affected by many factors, e.g., quality, training time, adaptability, generalization. For example, deep learning may be a better choice for cost estimation while reinforcement learning may be a better choice for join order selection. The training time may also be important, because some applications are performance critical and cannot tolerate long training time. 

%, which usually cannot be satisfied in database. Second, any AI model needs relatively long training time, which is usually intolerable in database.

\hi{Model Convergence.} It is very important that whether the model can be converged. If the model cannot be converged, we need to provide alternative ways to avoid making bad decisions. For example, in knob tuning, if the model is not converged, we cannot utilize the model for knob suggestion.   
 
\hi{Adaptability.} The model should be adapted to different scenarios. For example, if the hardware environments are changed, the model can adapt to the new hardware. 
  
\hi{Generalization.} The model should adapt to different database settings. For example, if the workloads are changed, the model should support the new workloads. If the data are updated, the model should be generalized to support new data. 
 

\subsection{DB4AI}

\hi{Accelerate AI algorithms using indexing techniques.} Most of studies focus on the effectiveness of AI algorithms but do not pay much attention to the efficiency, which is also very important. It calls for utilizing database techniques to improve the performance of AI algorithms. For example, self-driving vehicles require a large number of examples for training, which is rather time consuming. Actually, it only requires some {\it important examples}, e.g., the training cases in the night or rainy day, but not many redundant examples. Thus we can index the samples and features for effective training. 


\hi{Discover AI Models.} Ordinary users may only know their requirements, e.g., using a classification algorithm to address a problem, but do not know which AI algorithms should be used. Thus it is important to automatically discover AI algorithms. Moreover, it is also challenging to reuse the well-trained AI models by different users. 



\subsection{Edge Computing Database.} Most databases are designed to be deployed on servers. With the development of 5G and IOT devices, it calls for a tiny database embedded in small devices. There are several challenges in designing such a tiny database. The first is database  security to protect the data. The second is real-time data processing. The small device has low computing power, and it is rather challenging to provide high performance on such small devices. The third is data migration among different devices. Some devices have small storage and it is challenging to migrate the data across different devices. 



%\hi{Security}

%\hi{Database function As a Service}



%, and deploy the  automatically designed database for different .  

%Note that different databases usually adopt the common techniques, e.g., index and cost-based optimizer, but 

%The database architects 
%As Figure~\ref{fig:ANDB} shows, AI-native database can support AI and DB services naturally and efficiently. It brings new opportunities to the development of database. However, due to the demands of AI algorithms (e.g., training data), as well as problems in DB technology itself, there are still several challenges in the process of deploying such a design.

%\subsection{Challenges in AI}
%\label{sec: ch-AI}
%Challenges in AI is mainly around two aspects. First, any AI model needs large-scale and high-quality training data to achieve good performance, which usually cannot be satisfied in database. Second, any AI model needs relatively long training time, which is usually intolerable in database.

%\subsubsection{Lack of training data}
%\label{subsec: data}
%AI algorithms rely on training data heavily, including the quality, number and diversity of samples.

%$\bullet$ \textbf{Sample Quality}. Sample quality has the most direct impact on the quality of model training. In order to train the prediction model correctly, the sample data must be correct and de-duplicated. But it is difficult to guarantee the data quality in the database system. Firstly, although the database system has abundant statistical information, many of these information are not real-time updates, such as the statistical information of relational tables. Secondly, these data will be affected by many factors, such as cardinality estimation, not only the data distribution information of relational tables, but also the execution cost of various physical operations of the database.

%$\bullet$ \textbf{Sample Number}. High quality samples alone are not enough to train robust AI models. Taking neural network as an example, if the training samples are very small and the number of updates of connection weights is small, the space that the model can explore is very limited. And the adaptability of the model can be weak. While in DB, many problems can hardly provide enough training samples. For example, for workload forecasting, user data in real scenarios are often hard to get, under strict protection.

%$\bullet$ \textbf{Sample Diversity}. Although the mature machine learning model can adapt to new problems, providing typical samples in training stage can accelerate the convergence speed of the model and improve the accuracy and adaptability of the model. However, in database-related problems, due to the limited training time allowed, it is often difficult to obtain sufficient and diverse data in the initial training stage. For example, in the tuning problem, the training stage often only provides several typical benchmark workloads.

%\subsubsection{Unaffordable Training Time}
%\label{subsubsec: time}
%Data alone is not enough for machine learning. The learning model needs enough training time to transform input knowledge into output knowledge. Therefore, in fact, simple classifiers can be widely used, because training complex classifiers takes a long time. Similarly, it is difficult for database systems to converge when they are faced with various user needs. Therefore, there are two requirements for the selection of machine learning algorithm in database system. First, the model adapts to the scenario. For example, in tuning problem, many parameters have continuous ranges of values, and algorithms such as Q-learning need to keep large-scale tables, which wastes time and resources. Secondly, it combines gradient descent and transfer learning to improve training efficiency. Up to now, many algorithms have been proposed to optimize training efficiency. For example, in reinforcement learning, Actor-Critic algorithm can enhance the convergence speed with the Critic evaluating the behavior of the Actor.

%\subsection{Challenges in DB}
%\label{sec: DB}
%Here we mainly consider the challenges that DB can bring about to AI. There are three problems.

%\subsubsection{Various Hardware}
%\label{subsec: hardware}
%The challenges of the hardware environment include two aspects. 

%$\bullet$ Hardware on which database processes transactions. New computing and storage media are emerging, with ROM like  SSD, disk array, NVM and CPU architectures like SMP, AMP. People often configure different for thier databases, considering many factors (e.g., budgets, applications). And in cloud environment, much more hardware instances exist. Different hardware environments can have a great impact on AI technology. For example, in knob tuning, many parameters are strongly related to hardware, such as the cost of reading/writing tuple, the overhead of database operators and so on. The model will take a long time to correct the historical cognition without taking the hardware changes into consideration. 
%For example, in cardinality estimation technology, if the system supports multiple threads (workers) to execute a query plan in parallel, the relationship between operator overhead at different levels is no longer simple summation. Machine learning model needs more time to adapt to the change of implicit rules. 

%$\bullet$ Hardware on which AI model is trained. In order to reduce the time used to train large-scale machine learning models, Intel, Google, Microsoft and other manufacturers have released a variety of hardware specifically to help train AI models (e.g., GPU, TPU, FPGA). Altough those hardwares improve the efficiency of matrix computing, they require the corresponding adjustment of machine learning algorithm to adapt. For example, For example, if you want to migrate an AI model from CPU to GPU, you need to migrate tensors, variables and the model to the display memory in GPU.

%\subsubsection{Various Workload}
%\label{subsec: workload}
%Various workloads pose challenges in two aspects.

%$\bullet$ With different workloads, the database not only needs to provide appropriate operation and maintenance strategy, execution plan, processing flow, but also needs to provide appropriate architecture to store data. For example, in edge computing, we need to provide services nearby, and there are some problems such as data/service migration; in cloud database, it manages data uniformly and maintains diverse distributed clusters. Firstly, that requires AI model to filter out the important factors in the workload, and dynamically adapt to changes. 

%$\bullet$ Hybrid application services increase the complexity of database management.  Different workload types often correspond to different services, such as OLTP, OLAP and HTAP. And many applications require hybrid services. For example, banking system not only provides transactional business, but also needs analytical business such as data auditing and analysis. So database instances can no longer serve one type workload. This kind of composite business has higher requirements for database storage, processing and data management. This requires that the machine learning model trained from a single scenario can provide a good enough service for hybrid workload types.

%\subsubsection{Various User Requirements}
%\label{subsec: requirement}

%Different users often notice different database performance. For example, real-time services require low query latency, while batch services require high throughput. In order to guarantee the desired performance, databases often need to sacrifice the performance of other aspects. For example, in order to improve the utilization of the overall resources, the number of parallel connections can be increased, but the workspace allocated for each connection will be reduced, which will affect the execution efficiency of a single task. In cloud databases, there are a variety of user "preference". In order to use machine learning to optimize database technology, it is necessary that machine learning model can automatically and quickly adapt to the requirements of different users, and allocate resources reasonably based on priority. 
%And use various statistical, caching, data collation mechanisms (such as vacuum) to improve resource utilization and fault-tolerant disaster prevention capabilities, improve resource utilization and database stability, and further enhance user experience.



