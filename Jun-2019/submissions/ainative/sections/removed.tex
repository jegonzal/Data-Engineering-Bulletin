%!TEX root = ../main.tex
  





%For example, in PostgreSQL there are 38 operations.


%two cost values: Total Cost denotes the time when all the resulting rows are returned and Startup Cost denotes the time when the first row is returned. As figure \ref{fig:size_time_cost} shows, the optimizer can give relatively accurate cost estimation and perform steadily for varying data-set size. 


%Following the practise of PostgreSQL, we also define the query cost as the vector of execution time of each database operation. 

%So as figure ~\ref{fig:encoding} shows, based on the query optimizer in the database, we extract the query plan first and then obtain query cost as follows. First, for each node we add two attributes, Child Cost representing the time when all the child operations return at least one row and Feature Cost representing the time from starting to process to outputting the last row. Since it's possible for an operation to work only when all the operations in the child nodes return at least one row, we denote Feature Cost as (Total Cost - Child Cost). Second, we use a bottom-up strategy to compute the Feature Cost: 1) Initiate the Child Cost of every node by 0; 2) From bottom up, for each node n, its Feature Cost equals to (Total Cost - Child Cost). 3) If n is not the root and n's Startup Cost is larger than its parent node's Child Cost, set its parent node's Child Cost to n's Startup Cost.  

%To this end, Feature



%The cost information captures the query cost of processing the query in the database. However, a query usually has many possible plans and each plan has different costs. So it is not realistic to directly parse the query statement to extract the cost. Instead, we utilize the query plan generated by the query optimizer, in which each node has the estimated execution cost. As Figure ~\ref{fig:size_time_cost} shows, the optimizer can give relatively accurate cost estimation and perform steadily for varying dataset size. So based on the query optimizer in the database, we extract the query plan first and then obtain the cost as follows. Each node (e.g., aggregate, hash join, sort) on the query plan maintains an accumulate cost in the subtree of this node. For example, considering the query in Figure~\ref{fig:encoding}, the cost of the root is the total cost of the nodes under the node. To compute the actual cost of each node, we need to subtract the cost of its children. To this end, we can use a bottom-up traversal to compute the cost. Next, we need to aggregate the node based on the operation, e.g., aggregation based on sequential scan and hash join. 
%In summary, for cost information, we maintain a $|P|$ dimensional vector, where $P$ is the set of operations in database, shown in Table~\ref{tbl:dbOp}, and $|P|$ is the number of operations. For example, in PostgreSQL there are 38 operations. \lgl{add a table to show these operations} \lgl{how about other db?}




% select min(tbl3.movie_id) from info_type as tbl1, movie_cimpanies as tbl2, movie_info_idx as tbl3 where tbl1.info = "bottom 10 rank" and tbl2.movie_id = tbl3.movie_id and tbl1.id = tbl3.info_type_id



%\begin{figure}[!t]\centering
%\includegraphics[width=.5\textwidth, height=.5\textwidth]{tuning_figs/query_encode_xx.eps}
%\caption{Character Encoding}
%\label{fig:encoding}
%\end{figure} 



%For each base table, it corresponds to a boolean variable in our query feature vector, in which 1 means that the table is used and 0 not. We perform logical AND operation on each bit of the vector's data information part. The result shows an overall view of data requirement, or from the point of view of tuning, the data possible to be fetched from the disk.
% in the query plan, including filtering, arithmetic calculation, all kinds of join operations and etc.  \lgl{add a table to show all the cost.} Those costs make up the cost features in our query feature vector. 


%Our tuning model aims to provide a suitable operating environment for the execution of the queries. So it is important to integrate related query information into our tuning model so that it can learn from that knowledge. Firstly, there are two problems we need to figure out: 1) Which features need to be extracted from the query; 2) What information the query lacks but is important to the tuning problem.

%The system parameters are mainly about the configuration of the operations in its components and the allocation of system resources []\lgl{add ref}. So in general, there are also two aspects of information: 1) Data information: the base tables involved in the query; 2) Operating information: the costs in the key steps to process the query. In the following subsections we will talk about the featurization of the data and cost information and the way of character encoding in further details.




\iffalse
%\lgl{considering a knob **,  \texttt{ContinuousTuner} recommends a value between, while \texttt{DiscreteTuner} recommends a value in \{-1, 0, +1\}} C


%\texttt{Query Analyzer} includes two sub-modules, \texttt{Query Planning} and \texttt{Vectorization}. The former generates the query plan based on the database optimizer, and the latter extracts features from the query plan and generates the feature vector. 


\subsection{Workflow of \large{\oursys}}
\label{subsec:def:workflow}

Our system supports three types of tuning requests based on different  granularities of tuning requests. 


\vspace{.25em}
\noindent{\bf Query-level Tuning.} The first is query-level tuning, which tunes the database knobs for each query. This method can optimize the latency for each query but may not achieve high throughput, because the queries cannot be concurrently tuned and processed (e.g., when we tune the knobs for a query, the system cannot process other queries). For each query-level tuning request, \texttt{Query Analyzer}  generates a feature vector. \texttt{ContinuousTuner} takes this vector as input, recommend continuous knob values, and the system executes the query based on the recommended knob values.

 
\vspace{.25em}
\noindent{\bf Workload-level Tuning.}The second is workload-level tuning, which tunes the database knobs for the whole query workload. This method cannot optimize the query latency, because different queries may require to use different knob values. This method, however, can achieve high throughput, because different queries can be concurrently processed after setting the newly tuned knobs. For each workload-level tuning request, \texttt{Query Analyzer}  generates a feature vector for each query and then merges them to generate a unified vector. \texttt{ContinuousTuner} takes this uniqued vector as input, recommend knob values, and the system executes the queries based on the recommended knob values.

\vspace{.25em}
\noindent{\bf Cluster-level Tuning.} The third is cluster-level tuning, which partitions the queries into different groups such that the queries in the same group should use the same tuning knob values while the queries in different groups should use different knob values, and then tunes the knobs for each query group and executes the queries in each group in parallel. This method can optimize both the latency and throughput.  To enable cluster-level tuning, \texttt{Query Analyzer} first generates a feature vector for each query in the group and \texttt{ContinuousTuner} learns a configuration pattern for each query which can capture the knob values that best match the query. However, \texttt{ContinuousTuner} may be expensive to generate the configuration pattern for all the queries. To improve the performance, we propose a deep learning model, \texttt{DiscreteTuner}, which learns  the discrete values values for the knobs. Then the \texttt{Clustering} classifies these queries based on their discrete configuration patterns. Note that  \texttt{DiscreteTuner} uses deep learning to predict the configuration pattern for each query, which also involves a training step, where each training tuple is $\langle q, p\rangle$, where $q$ is a query and $p$ is a discrete configuration pattern. For example, \lgl{considering a knob **,  \texttt{ContinuousTuner} recommends a value between, while \texttt{DiscreteTuner} recommends a value in \{-1, 0, +1\}} Considering the knob $host\_cache\_size$ in MySQL, which limits the size of the host cache, \texttt{ContinuousTuner} recommends a value between 0 to (64-bit platform) 65536, while \texttt{DiscreteTuner} recommends a value in \{-1, 0, +1\}.



%.which is the recommended pattern by  \texttt{ContinuousTuner} that best matches the knob values for the query.  

After clustering, for each query group, \texttt{ContinuousTuner}  recommends appropriate knobs and then the database executes these queries based on the new knob values. 

%\texttt{ContinuousTuner}  uses the deep reinforcement model DS-DDPG to tune the model and recommend the configuration. 

 
\noindent {\bf ContinuousTuner.} \texttt{ContinuousTuner} recommends knob values for a single query or a group of queries.  In offline training,  \texttt{ContinuousTuner} gets some training queries, and uses the deep reinforcement learning method to train the model; in the online tuning step, given a query (or a query group), \texttt{ContinuousTuner} uses the trained model to recommend continuous  knob values. 


\noindent {\bf DiscreteTuner.} \texttt{DiscreteTuner} recommends a configuration pattern for a single query.  In offline training,  \texttt{DiscreteTuner} gets some training tuples, and uses deep learning to train the model which estimates a pattern for each query; in the online tuning step, given a query, \texttt{DiscreteTuner} uses the trained model to recommend the discrete configuration patterns.


\fi
%\includegraphics[width=19.5cm, height=7.5cm]{tuning_figs/workflow_0.eps}


% for each SQL query,  which interacts with the clients, passes the incoming queries to our system and returns the desired results from the database. The $\pmb{Query\ Analyzer}$ is responsible to estimate the operating costs in the queries and vectorize the plans into feature vectors. 
%This repository mainly includes three schemas: Table$\_$1 (query, configuration) for training the ML model in the Query Analyzer; Table$\_$2 (query, state change) for training the Predictor and Table$\_$3 (state, action, state', reward) for training the Actor-Critic module in the tuning model.

% If the queries support batch processing and do not require to be executed in order (or insensitive to latency), such as the OLAP workloads, the feature vectors are inputted into the 

%Otherwise, all the queries are classified into one class. 
% according to the compound observation value that is the combination of the predicted state changes and the database's current state. The predicted state changes are devised by the Predictor module in DS-DDPG, which is a neural network taking the feature vector as input. 
%We will explain more details of \texttt{AutoTuner} in Section~\ref{sec:tunner}.


%There are two events our system needs to process: 1) Give a proper configuration pattern for each query; 2) Tune the database while executing queries at DBA's command. Based on the workflow in Figure~\ref{fig:workflow}, we give an example ($example $~\ref{sec:overview}.1) to show how our system handles these two events.

%\begin{example}
%  In Figure~\ref{fig:architecture}, the dotted (brown) lines represent the configuration mapping process, and the solid (read) lines represent the tuning process:

  %      (1) When training QTune, it's easy to get the training data for neural networks in the DS-DDPG model by counting the difference of database state before and after query execution and utilizing the reward function, which will be further talked in Section~\ref{sec: tunner}. While the DL model in Query Classifier also needs many high quaility samples (V, P), where V is the query features that can be parsed from the query plan and P is a configuration pattern under which the database can execute the query efficiently. This process just helps to find a possible (V, P) pair for each query of clients.

%        As clients request for access through the local interface, the queries are buffered (step A). For each cached query, the Query Analyzer conducts vectorization (step B). It generates corresponding query plan tree, in which each node contains the information of a base table or a basic operation, including its start-up cost, total cost and rows involved. Cost denotes the estimated execution time. Based on the query plan, it constructs a feature vector V. This vectorization procedure will be further explained in Section~\ref{sec:query}. The task feature vector V' equals to V here. And the Predictor estimates the possible state changes C based on V' (step C). Vector C is sumed up with the database state vector S to form the observation S' (step D). The agent (the Actor-Critic module) takes S' as input and decides an action (step E), which is the recommended configuration for this query. Database re-configures itself based on this recommendation and executes the query (step F). If the performance is good enough, A is adopted as P for this feature vector V and (V, P) is stored as a training sample (step G). Otherwise, repeat the above steps until the performance is good enough, e.g., latency is cut down by 40$\%$.

%(2) When the DBA issues a tuning request, he also needs to initiate QTune by passing the performance metrics and the corresponding weights for the reward function (step 1). $\{latency: 1, throughput: 0\}$ means only latency is considered in measuring the database performance. And then the tuning system starts working. In this example, there come fifty queries (step 2). They are first vectorized (step 3): Query Analyzer produces the query plan by calling the database's query optimizer and extracts information from the plan to form a feature vector V. After characterizing the query features, they are passed into the \texttt{Query Classifier}, in which a DL model maps each query to a proper configuration pattern (step 4) and then it uses $DBSCAN$ to classify these queries based on these patterns (step 5). For the feature vectors in each class, they are summed up to form the task feature vector V' (step 6). Then the \texttt{Predictor} produces the predicted database state changes C (step 7) according to V', the database system provides the current state $S$ and the sum of $C$ and $S$ forms the predicted next database state $S'$ (step 8), denoted as the $observation$ in the DS-DDPG model. The $Agent$ accepts $S'$ and recommends a configuration $A$ (step 9). The manipulator (a rule-based loop program) checks the legality of $A$ and then issues the reconfiguration command to the database system (step 10). After re-configuration, the database actually executes these queries and returns the results to the corresponding clients (step 11). And the database system will feed back the performance information (step 12). All the recommendations and performance information are periodically reported to the DBA. And the useful tuning information is stored as the taining data on a separate disk space (step 13), including what queries, under what configurations, how much state change is caused and how the database performs (WWHH).
%\end{example}	

%, as the optimization function. At step $i$, after gaining $E$, it first computes the gradient $g_i$ = $\partial E / \partial \theta$. $m_i$ and $v_i$ are estimates of the mean and the uncentered variance of the gradients respectively. They are updated by $g_i$: $m_i = \beta_1  m_{i-1} + (1 - \beta_1 )g_i$ and $v_i = \beta_2  v_{i-1} + (1 - \beta_2 )g_i$, where $\beta_1$ and $\beta_2$ are exponential decay rates. After computing bias correction $\widehat{m}_i = m_i/(1 - \beta_1)$ and $\widehat{v}_i = v_i/(1 - \beta_2)$, $m_i$ and $v_i$ are used to update the network weights: $  \theta_i = \theta_{i-1} - \frac{ \alpha }{\sqrt{\widehat{v}_i} - 1} \widehat{m}_i\ $.


%Figure~\ref{fig:neuron} shows the data transformation procedure in a neuron pass. 


%Here the data information for our query feature vectors is only about the underlaying relation tables and materialized views. In this paper we name them $base\ tables$ for simplicity. These base tables are physically stored on the disk and are the vary starting points to iteratively generate temporary tables and get the result finally. According to the data information and the caching of the database, the tuning model decides whether the system resources are enough to provide relatively optimized performance for those queries. For example, whether the remaining buffer is large enough. 

%The reasons the other data-related concepts are not included are 1) for the current RDBMSs, to read a column, the relation table where it belongs needs to be fetched into memory first. So the column information can actually classified into the operating cost; 2) except for the materialized views, the other database structures used in a query, such as $view$ and $stored\ procedure$, are virtual structures that do not actually store data but pre-kept query commands []. Instead of directly including these virtual structures into the data information, we parse them recursively and fetch the vary used relation tables or materialized views. 


%To convert the query plan information to our cost features, we also follow a bottom-up strategy: from the vary last non-leaf level of a query plan tree, for each node in the same level, the cost value is added to the corresponding cost feature (initialized by 0) and the value is reduced from its parent's. It iterates until the root node's value is used. This way, in O(n) complexity, we convert a query plan tree into a set of cost features. Actually we can see that the data information can be directly devised from the bottom level of the query plan.

%A query plan is generated based on a bottom-up strategy. Taking all the base tables as leaf nodes, each non-leaf node represents a database operation that is to be performed on the temporary tables of its children nodes (the result of the corresponding operation). And the cost in the non-leaf node is the total cost to build the sub-tree with that node as the root. By using the query optimizer in the database to be tuned, we can generate a query plan that is similar to that used to actually execute as much as possible. 


%The database maybe updated 
%After extracting the data and cost information from the query plan, we need to encode these characters to form a feature vector to represent the useful query information for the tuning problem.

%As figure~\ref{fig:encoding} shows, the encoding procedure is divided into 2-step. In the first step, the query optimizer generates a query plan tree for each query. In the next step, the tree is divided into 3 parts: the root node gives the query type information (such as insert, delete or read); the non-leaf nodes shows the estimated cost in each step to execute the query; and the leaf nodes are of the physical tables. Each part is mapped into features in the query feature vector. The first bit is an integer  encoding the query type, like $read$  is mapped to 0 and $update$ is mapped to 1. And the second to (M+1)th positions are operation costs: each position (an integer) corresponds to the total cost of a specific database operation. And the rest positions are for data information. As mentioned above, each position is of boolean type to show whether this query uses the corresponding table (1 if yes). 

%For the feature vector, we can see that the cardinality of the first two parts is relative stable: in traditional  RDBMSs, the query types are mainly select, update, delete and insert, plus some management orders (alter, set, ..) and analysis orders (explain, analyze, ...). And for a specific database, there are limited database operations. For example, there are 38 operations used in PostgreSQL. However, the data information can vary from time to time, especially under the high-write workloads. To cut down the loss caused by dropping or creating a table, we take two measures: 1) place the data information at the end of the vector; 2) for a relative long time (till next off-line training), each position of the data information can only represent a fixed table even if the table is dropped. There is a dictionary recording the mapping from table names to integer values, which denote the corresponding position in the feature vector. If there are new tables created, new items will be added to the dictionary. Instead of directly appending, we first lookup the dictionary: if we find a item of the same table name but has been dropped, this table can directly reuse this position. The reason behind this action is that the detailed table information (cardinality or attributes) is reflected in the cost information. This table information only gives the total table scale in the later part. 
  
%After those three parts are determined, each feature vector is padded into the same length even if there are continuous 0s at the end, whose length equals (1+|database operation| + |table dictionary|). In case the fast growth in feature scale brings too much overhead to the tuning model, we also set a monitor (a script) to check the dropped table number, once the number exceeds a threshold, we advance the  job of cleaning the dropped tables from the dictionary.

%For the feature vectors whose queries are of the same class, the same positions of the first two parts in the vectors are added. And we perform logical $AND$ operation on the rest positions. For the $AND$ operation, if the result is 1, it is replaced by the cardinality of the corresponding table and no changes if it is 0. Then the results of the three parts are concatenated to form the overall feature vector of the queries to be executed together.



% \lgl{For example, in MySQL, $innodb\_buffer\_pool\_size$ limits the size of buffer pool. By setting the knob as large as possible (up to 70 percent for InnoDB), most read operations can be finished in memory and currently it can be thousands of times faster than on disks. Although knobs such as $lock\_wait\_timeout$ and $max\_seeks\_for\_key$ do not have so obvious relations with performance, they take effect by controlling the operating mechanisms. Not Good!} 
% \lgl{add more limitations of CDBTune here!!!!! Detailed problems will be discussed in section \ref{sec:tunner}. }
%~\cite{DBLP:conf/sigmod/AkenPGZ17, DBLP:conf/sigmod/cdbtune19, DBLP:conf/cloud/ZhuLGBMLSY17} and DBAs. 


%\lgl{what is the contribution for deep learning? more details!!}

%to solve the problems in traditional DRL methods for tuning (see Section~\ref{sec:tunner}).  
% Latter in the experiment part (section \ref{sec:experiment}) we will prove our system gains significant performance improvement, compared with CDBTune using the DRL method but without taking query features into consideration.\lgl{?????}.  To integrate query information, %\lgl{say the difference of our DRL with CDBTune. what is our advantages?} 
%DBAs are short on the cloud. Instead we need to automate the tuning process.
%Database configuration tuning is becoming more and more important in database operation and maintenance~\cite{DBLP:conf/sigmod/AkenPGZ17, DBLP:conf/icde/BelknapDDY09, DBLP:conf/vldb/WeikumMHZ02}. Configuration parameters (knobs) control nearly every aspect in a DBMS~\cite{DBLP:journals/pvldb/DuanTB09} and affect database performance to varying degrees. For example, under heavy burden, increasing IO thread number can significantly improve throughput, but choosing different audit logging strategies is less influential. There are hundreds of such knobs in a DBMS and it is an NP-hard problem to select appropriate values for them~\cite{DBLP:conf/sigmod/AkenPGZ17}. Besides, the optimal configuration patterns vary with many factors, such as workloads and hardware environments.
 % Traditionally, big enterprises hire DBAs to tune database configurations. But even the most experienced experts only adjust a small percent of knobs and need much time to experiment on different configuration schemes. It is costly no matter in money or time. So many tuning tools such as MySQLTuner~\footnote{https://github.com/major/MySQLTuner-perl} appeared to help to finish this work. But the problems are: 1) They give tuning advice according to experiments on a handful of samples, which is not convincing enough. 2) Most of these tools are only for a specific database; 3) The work for human beings is still heavy to actually choose the knob values. This problem is extremely severe for the providers of cloud database services. It is because they have to meet a large number of users' performance requirements on varying database environments. DBAs are short on the cloud. Instead we need to automate the tuning process.
% Previous studies in automatic tuning methods are not satisfying enough~\cite{DBLP:conf/sigmod/AkenPGZ17, DBLP:journals/pvldb/DuanTB09, DBLP:conf/cloud/ZhuLGBMLSY17}. BestConfig~\cite{DBLP:conf/cloud/ZhuLGBMLSY17} searches for the optimal configuration by sampling from the whole configuration space. The problem in it is 1) It is a heuristic method and can not ensure finding satisfying results in limited time; 2) It can not utilize the history experience. Each time a new tuning request comes, it restarts the tuning process. Considering these problems, OtterTune~\cite{DBLP:conf/sigmod/AkenPGZ17} proposes to build a learning-based model to learn the correlations between workloads, knobs and performance metrics. But 1) The pipeline learning model suffers from  information loss at each stage. For example, It filters out many knobs according to the regression results before mapping values for the knobs; 2) The machine-learning model (Gaussian Process) is too simple to work for hundreds of knobs. 


%The tech of Deep Reinforcement Learning (DRL) brings new promise to configuration tuning. Thanks to the hardware revolution in recent years, the cost of GPUs or even TPUs for large scale deep learning is dropping and it is more realistic to apply this tech to the database domains~\cite{DBLP:conf/cidr/KraskaABCKLMMN19, DBLP:conf/sigmod/MarcusP18, DBLP:conf/sigmod/OrtizBGK18}. But currently only CDBTune~\cite{DBLP:conf/sigmod/cdbtune19} has utilized this tech in configuration tuning and there are many problems in it 1)  Directly use the existing DRL model (DDPG), which is not entirely suitable for this problem; 2) Only take database state into consideration. And it is slow to adapt to the changes in workloads. 3) It only tunes in workload level. Each time the tuning request comes, it needs to repeat running the model until the configuration is suitable.

%Besides, since queries in the same workload may have different optimal configuration patterns, for the whole workload \oursys needs to  devise a tradeoff tuning plan. So we propose a multiple granularity strategy: 1) Query level. \oursys works for each query and database executes queries in single thread. This way we achieve good latency but bad throughput; 2) Workload level. \oursys tunes once for the whole workload and database executes queries in maximum thread number. This way we achieve good throughput but bad latency; 3) Cluster-level. For scenarios where execution order does not matter, such as OLAP applications, we can divide queries into different clusters and run \oursys in cluster. This way we can strive a balance between throughput and latency. The detailed clustering strategy is discussed in section~\ref{sec:cluster}.
%to learn and conduct configuration tuning.

%integrate the query information into our system by extending and vectorizing the query statements. This information helps the DRL model recommend suitable configurations. Besides, \oursys can dynamically adapt to the changes in workloads.

%\lgl{which is the contribution? more details!!} 1) 




 
%Under scenarios where execution order does not matter, each time we input queries into the DRL model by groups to reduce confusion caused by diverse suitable configurations among the queries and help the model to work more efficiently and gain better performance. \lgl{(However, the group size matters to overall performance)}


%(4) \oursys supports tuning requests in multiple granularities. With query clustering technology, it's more efficient in data analysis transactions.%And it can adapt to workload changes and hardware environment migrations with superior performance.



%\texttt{Actor} takes the metrics $S'$ and the score as input, updates the weights of its  neural network, and makes an action (tuning the configurations).  
% to make the real database metrics approaching $S'$. 
% \texttt{Actor} updates 
% the environment manager. It decides how to manage the environment's inner state by giving an action according to the observation.
%It works by accepting the input query features and outputting the predicted state changes.  
%the 19 attributes in table pg\_stat\_database compose %And the the inner state is just the database configuration. \lgl{give examples} 
%The \texttt{Workload} simulates the users who issue queries to the environment. 
%and affected by the agent's action
%\noindent \textbf{Workflow}. At time $t$, the workload generates $n$ queries. Firstly,  \texttt{Analyzer}  parses these queries and produces a feature vector.Then \texttt{Predictor} evaluates the query features and predicts the state changes. The combination of the state changes and the outer state is denoted as the observation and is sent to the Agent.  In the Agent,  \texttt{Actor} gives an action according to the observation and the \texttt{Critic} produces a score (Q-value) based on the observation and the action. The \texttt{Actor} network utilizes the score to update its weights.  At the same time, the environment is reconfigured according to the action, the recommended configuration in our tuning problem, causing the inner state changes. After re-configuration, the environment executes these queries and computes the reward based on the performance. The outer state changes and the critic network uses the reward value to update its weights.

%\lgl{not clear! map the action and state to the database}

%In this part we use different number of system knobs in QTune and observe the relationship between the knob number and the performance, including the throughput, latency and training time, that is, the time required for model to converge. We conduct this experiment using Sysbench(RO) benchmark on PostgreSQL. We also need to explore the proper way of choosing a relatively optimal knob set for tuning. So we try two strategies to iteratively add knobs: 1) Random selection. Each iteration, we randomly choose a fixed number of knobs for tuning. 2) Impactful first. Knobs have different effects on database performance and by experience we divide the system knobs into impactful knobs and extended knobs. Each iteration, we choose a fixed number of knobs first from the impactful knobs. After the impactful knobs run out, we choose from the extended ones.\lgl{Add table of impactful knobs}

%PostgreSQL has 181 dynamic knobs, whose context is PGC$\_$USER, PGC$\_$SUPERUSER or PGC$\_$SIGHUP, in which 136 knobs are of numerical or boolean types. The other knob types we do not consider because they are mainly about item names and has few things to do with the database performance. Besides, they need to be quantified before taken into consideration. This procedure causes much loss in accuracy and brings about unnecessary noise. Figure~\ref{fig:num_important} and figure~\ref{fig:num_random} show the results of incrementally adding knobs in those two ways. The point where the knob number is 0 represents the trial under default configuration. 

%Since the very time consumption part in training a network is to update its weights when it needs to do many many matrix operations, increasing training time is mainly caused by the larger network scale and the more complex input patterns for the network to learn from.




%And its training time can even be lower by 11.9$\%$ at most. Because the impactful knobs, such as buffer size, connection concurrency and fetching factors, can significantly affect the performance. And their relationship with the performance is usually not very complex. For example, increasing the buffer size within the hardware limit can always gain better throughput under heavy workload. So using the impactful knobs can help the learning of the neural networks very clearly and efficiently. By comparison, randomly choosing knobs can bring about many knobs that has little effect on the performance or is of complex relationships with the other knobs and the database performance. It leads to longer learning time and less obvious performance gains. 

%So in the real implementation, our knob selection strategy is in two-steps. 1) Take all the impactful knobs (by DBA's experience and the training reports) into consideration; 2) If better performance is required and models have already been well trained, add extended knobs into QTune incrementally.

%\subsection{Evaluation by varying knobs}
% env: JOB benchmark for PostgreSQL%erify that 1) The tuning time is negligible compared to the execution time of processing queries; 2) Different tuning requests in different granularities have their own strengths and weaknesses; 3) It is not useful to add attributes and operations to our feature vector;  4) \oursys has better performance than existing four tuning methods; 5) For different workloads and databases, \oursys can provide high tuning quality; 6) \oursys  has great generalization ability in handling new queries and adapting to new hardware environments.


%We use three query workloads JOB, TPC-H and Sysbench. Table~\ref{tbl:benchmark} shows the details.

%Dynamic knobs indicate the knobs that can be changed without restarting database. Since restarting database is usually expensive for enterprises, here we only utilize dynamic knobs in tuning. And the queries in Sysbench are temporarily generated for each new workload. Running Sysbench in RW mode for 10 minutes and about 474000 is produced.


%1. Evaluation on our method:     1. Different Granularities     2. Varying \# of Knobs     3. Different vector features   4. Tuning Time and Training Time

%\noindent {\bf Experimental Setting.}

% once a configuration pattern is produced by the DL model, we re-run DBSCAN on all the existing configuration patterns. And here the clustering time only considers the time to run DBSCAN for the current query.\lgl{classifier?}

%%% Background-RL
%\subsection{Reinforcement Learning}
%\label{subsec:def:rl}
%\vspace{-.25em}	
%$Reinforcement\ Learning$ is a framework that enables the agent to learn from the interactions with the environment in discrete time steps, with the goal of maximizing the reward. At each time slide t, the agent receives an observation $o_t$, which reflects the state of the environment. It then takes an action according to the observation $o_t$ and its own policy $\mu$. The environment is affected by the action and changes its state to $s_{t+1}$. And it evaluates this action by sending a reward to the agent. Periodically, the agent updates its policy to maximize the expected cumulative reward R($s_t$. $a_t$) = r($s_t$, $a_t$) + $\gamma$r($s_{t+1}$, $a_{t+1}$) + ${\gamma}^2$r($s_{t+1}$, $a_{t+1}$) + ..., where $\gamma$ is the discount factor. Unlike supervised learning, it accumulates knowledge through trial and error by either exploiting the current situations or exploring unknown action space. In general, reinforcement learning can be classified into many branches, including the value-based, the policy-based and the actor-critic model which combines the two.
 
%Reinforcement learning algorithms that incorporate neural networks are called $\pmb{Deep\ Reinforcement\ Learning}$ (DRL). That is, deep neural networks are used to approximate some components of the RL model, such as the value function, the policy, the state transition function, and etc. Next we will give a brief introduction to DDPG, the method we are going to adopt in our tuning system.

%$\pmb{Deep\ Deterministic\ Policy\ Gradient}$ (DDPG) is an actor-critic approach, which uses two deep neural networks to approximate the policy function $\mu$($s_t$) and an actor-value function Q($s_t$, $a_t$) respectively. The actor network $\mu$($s_t$) accepts a state and deterministically maps it to an action $a_t$. And the critic network Q($s_t$, $a_t$) considers the state $s_t$ and the chosen action $a_t$ together and outputs a Q-value Q($s_t$, $a_t$), which represents the cumulative discounted reward. Compared with the other two classical DRL methods, Q$-$Learning and DQN, DDPG is capable of processing problems of  high-dimensional and continuous action space. In this paper, the database configuration is mapped to the action. It has many knobs ( in PostgreSQL, in MySQL, and etc.) and most of these knobs are continuous. So we adopt DDPG to recommend optimal configurations for the database according to the predicted states, which will be further discussed in Section~\ref{sec: tunner}.




%\begin{table}[!t]
%\vspace{-0.5em}
%\centering
%\caption{Performance comparison of encoding queries into E1 <DML, TableList, OpCostList> and E2 <DML, TableList, OpCostList, AttributeList, OpList> respectively. Performance includes Latency Reduction(LD) and Throughput Improvement (TI) compared with default settings. And we run JOB benchmark on PostgreSQL.}
%\label{tbl:discreteTuner}
%\vspace{-1.25em}
%{%\footnotesize
%\hspace*{-0em} \begin{tabular}{|l|c|c|}\hline
% \multirow{2}{*}{Level} & \multicolumn{3}{|c|}{Actor Network} \\

%\textbf{Schema} & \textbf{LD} & \textbf{TI} \\\hline


%Query-level(E1) & $\downarrow$ 90.22$\%$ & $\uparrow$ 273.52$\%$ \\\hline
%Query-level(E2) & $\downarrow$ 90.38$\%$ & $\uparrow$ 280.52$\%$ \\\hline


%Workload-level(E1) & $\downarrow$ 77.58$\%$ & $\uparrow$ 537.50$\%$ \\\hline
%Workload-level(E2) & $\downarrow$ 76.51$\%$ & $\uparrow$ 513.24$\%$ \\\hline

%Continuous Tuner(E1) & $\downarrow$ 82.73$\%$ & $\uparrow$ 360.24$\%$ \\\hline
%Continuous Tuner(E2) & $\downarrow$ 83.12$\%$ & $\uparrow$ 367.52$\%$ \\\hline


%Discrete Tuner(E1) & $\downarrow$ 80.99$\%$ & $\uparrow$ 425.99$\%$ \\\hline
%Discrete Tuner(E2) & $\downarrow$ 90.01$\%$ & $\uparrow$ 427.92$\%$ \\\hline

 % \end{tabular}
%}
%\end{table}



%Workload
%We further verify the performance of QTune under different workloads. JOB, TPC-H and Sysbench (Read-Write mode (RW)) on \lgl{PostgreSQL}. Figures~\ref{fig:benchmark_throughput}-\ref{fig:benchmark_latency} show the results. 

%We have the following observations. First, QTune achieves the best performance over the other four methods and 


%In the following subsections we will 1) Give a clear definition of the configuration "preference"; 2) Discuss two ways to solve the mapping problem; 3) Explain the clustering algorithm used in \oursys,


%We find that, although the overall latency and throughput are greatly improved, it's not that good for all the queries. As table~\ref{tbl:p_queryNum} shows, the database even performs worse for some queries than that under the default configuration. And the improvement also varies among the rest queries. The latency of JOB.5d can be reduced by 98.3$\%$ while TPC-H.7's only has 64.5$\%$ reduction. In comparison, we also run \oursys in {\bf query-level} for the same queries and we can see that 1) the suitable configurations differ among the queries; 2) the latency of each query gains improvement compared with that in workload-level. However, this single-thread mode can cause great loss in throughput. To balance the two aspects of performance (concurrency $\&$ similarity), we propose to cluster these queries according to their own configuration "preference". This way, the whole workload is divided into several clusters to input into DS-DDPG. 


%These knobs have two characteristics. First,  there are large number of knobs. Second, the knobs values are in continuous space and have  relatively large value range.  % the knob space is of high dimensions. Since there are hundreds of knobs in a database. 2) the knobs are all of numerical types, integer or float, and with relatively large value range.  
%For instance, \texttt{Lock wait timeout} is between 1 and 31,536,000 and \texttt{key buffer size} is between 1 to the buffer size, e.g., 1,073,741,824. So it is actually a tough problem to map a pattern including all the configuration information to any query. Besides, the detailed knob values can vary even if we run the same query in the system twice. So to simplify this mapping process, we discretize each knob : for each knob, 0 if around the default value, 1 if they are of positive correlation and -1 otherwise. This way, the queries whose trend in configuration pattern is similar can be clustered together. It cuts down on computing cost and keeps the stability of the configuration patterns. Then we introduce two methods of configuration mapping and analyze their advantages and weaknesses.


%\subsubsection{Strategy 1: Learning Continuous Configuration Patterns Using DS-DDPG}

%It is easy to find that the mission of the DS-DDPG model is just to recommend suitable configuration. So by running each query through \oursys we can obtain their own configuration patterns. It seems to be a sound and well idea, since the patterns are continuous and quite reliable. However, the vary problem is that it takes too much time. Although the time from a query enters \oursys to \oursys gives a sensible configuration pattern is relatively short, around tens of milliseconds as shown in the experiment part. But if there are hundreds or even thousands of incoming queries, the mapping time will be in seconds. This overhead usually is not tolerable, especially when the total execution time is short. It only can be applied when the estimated time reduction is much longer than that overhead. So besides these mthod, we need to propose a more general way to do this work.
 

%\subsubsection{Strategy 2: Learning Discrete Configuration Patterns Using Deep Learning}





% This way, the system can tune once for the queries in the same cluster and the recommended configuration meets the requirements of the most queries better. To fulfill this wish, the class label does not need to have any real meaning except dividing the queries and we can take it as an unsupervised learning problem. Since the label is of high dimensions and they have complex correlations, we choose to use \texttt{DBSCAN}, an efficient data clustering algorithm under that scenario~\cite{DBLP:conf/kdd/EsterKSX96}, to accomplish this job.


%The patterns that are in low-density clusters are marked as noise. It works mainly by the following steps:

%$\bullet$ Divide the training set into n dimensions. n is the cardinality of the knob label vector.

%$\bullet$ For each point in the samples, it forms an n-dimension shape around that data point, and then counts how many data points fall within that shape.

%$\bullet$ It counts this shape as a cluster. It iteratively expands the cluster, by going through each individual point within the cluster, and counting the number of other data points nearby. 

% {\tt DBSCAN} will continue this process until no other data points are nearby, and then it will search to form a second cluster. It is used to find associations and structures in the configuration samples that are hard to find manually but that can be relevant and useful to find patterns and predict trends. 

%After delivering this algorithm, each query has a class label representing which cluster it belongs to. The queries marked as noise are divided into the same class. Then our system tunes the database and executes the queries for each class. It is easy to find that the scale of a class (number of queries in a cluster) matters to the performance: too small can lead to resource waste and cut down the throughput; too large can cause loss in latency. So it's up to DBA to express his preference in performance improvement by adjusting the parameters $eps$ and $minPoints$ in the algorithm.


%how to classify the queries to optimize the overall performance in appropriate granularity.


\begin{table}[t]
\vspace{-1em}
\centering
\caption{Key steps and total time in training period on TPC-H (RO) on PostgreSQL. The hardware environment is completely a new scenario for the DBA. And \texttt{\oursys} is under workload-level.}
\label{tbl:benchmark}
\vspace{0.25em}
{%\footnotesize
  \hspace*{-0em} \begin{tabular}{|c|c|c|}\hline
  $\textbf{Method}$ & $\textbf{Key Steps}$ & $\textbf{Time}$ \\\hline
  
  DBA & Understand needs; practise tuning & two weeks \\\hline 

  CDBTune & Collect data; Train networks & 62 h \\\hline
  
  OtterTune & Characterization; Filter knobs; Tune & 55 h \\\hline
  
  BestConfig & Sample; Recursively Search & 42.4 h \\\hline 

  \oursys & Predict DB state; Collect data; Train & 28 h \\\hline
  
  \end{tabular}
}
\label{tbl:instance}
\vspace{-1.5em}
\end{table}



