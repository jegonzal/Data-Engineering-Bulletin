%!TEX root = ../main.tex

\section{INTRODUCTION}
\label{sec: introduction}


Databases have played a very important role in many applications and been widely deployed in many fields. Over the past fifty years, databases have undergone three main revolutions. 
% what how where example

The first generation is stand-alone databases, which address the problems of data storage, data management and query processing~\cite{DBLP:books/daglib/0006734}. The representative systems include PostgreSQL and MySQL. 
	
	%It centralizes data management under the supervision of the data experts and provides uniform interface to data. 
	%And it is mainly for single-machine applications. 
	%Examples include Postgre95 and the early IBM relational database systems. 

The second generation is cluster databases, which aim to provide high availability and reliability for critical business applications. The representative systems include Oracle RAC, DB2 and SQL server. 
 
	%Database clustering technique is to use multiple machines together to store the same data (data redundancy). 
	%It is mainly applied in fault tolerant environments.
%	Examples include Oracle RAC, MongoDB Replication, Master Slave Replication in MySQL and etc.

The third generation is distributed databases (and cloud-native databases), which aim to address the problems of elastic computing and dynamic data migration in the era of big data~\cite{DBLP:journals/jidm/FigueiredoBM10}. The representative systems include Aurora~\footnote{https://aws.amazon.com/cn/rds/aurora/} and GaussDB~\footnote{https://e.huawei.com/en/solutions/cloud-computing/big-data/gaussdb-distributed-database}. 
	
%	Firstly, with distributed processing, it can further distribute the workload among working nodes~\cite{DBLP:journals/jidm/FigueiredoBM10}. Secondly, with Database as a Service (DBaaS), cloud database allows companies to free up personnel and focus on important tasks. Besides, cloud database makes it easy to scale up or down their databases with virtual technology. 
%	It is mainly applied for data-intensive applications.
%	Examples include GCP, AWS RDS, Microsoft Azure and etc.

% big data era, database systems face three challenges. Firstly, the traditional empirical optimization techniques (e.g., cost estimation, join order selection, knob tuning) cannot meet the high-performance requirement for large-scale data, various applications and diversified users. We aim to  design learning-based techniques to make database more intelligent. Secondly, many database applications require to use AI algorithms, e.g., image search in database. We can embed AI algorithms into database, utilize database techniques to accelerate AI algorithms, and provide AI capability inside databases. Thirdly, traditional databases focus on using general hardware (e.g., CPU), but cannot fully utilize new hardware (e.g., ARM, AI chips). Moreover, besides relational model, we can utilize tensor model to accelerate AI operations. Thus, we need to design new techniques to make full use of new hardware. 

However, the traditional databases still have several limitations in the big data era, due to the large-scale data, various applications/users and diversified computing power.

(1) Traditional database design is still based on empirical methodologies and specifications, and require heavy human involvement (e.g., DBAs) to tune and maintain the databases. We use several examples to show that databases can be improved using AI techniques. First, databases have hundreds of knobs and it requires DBA to tune the knobs to adapt to different scenarios. Recently the database committee attempts to utilize machine learning techniques~\cite{DBLP:conf/sigmod/AkenPGZ17, DBLP:conf/vldb/qtune19,  DBLP:conf/sigmod/cdbtune19} to automatically tune the knobs, which can achieve better results than DBAs. Second, database optimizer relies on cost and cardinality estimation but traditional techniques cannot provide accurate estimation. Recently deep learning based techniques~\cite{DBLP:conf/cidr/KipfKRLBK19, DBLP:conf/sigmod/OrtizBGK18} are proposed to estimate the cost and cardinality which also achieve better results. Moreover, learning-based optimizers~\cite{DBLP:journals/corr/abs-1808-03196, DBLP:conf/sigmod/MarcusP18}, learning-based  index recommendation~\cite{DBLP:conf/hais/PedrozoNR18}, learning-based automatic view generation~\cite{DBLP:journals/corr/abs-1903-01363} provide alternative optimization opportunities for database design. Third, traditional databases are designed by database  architects based on their experiences. Recently some learning based self-design techniques are proposed, e.g., learned indexes~\cite{DBLP:conf/sigmod/KraskaBCDP18} and learned NoSQL database design~\cite{DBLP:conf/cidr/IdreosDQAHRLJGL19}. Thus we can utilize more AI techniques to enhance databases and make databases more intelligent.      


%They are not intelligent. Databases are unaware of workload type and try to use one mode to fit all. For example, the database parameters are static and need to be adjusted manually for different scenarios. 


(2) Traditional databases focus on {\it relational data model} and provide relational data management and analysis ability. However, in the big data era, there are more and more diverse data (e.g., graph data, time-series data, spatial data, array data) and applications (e.g., machine learning and graph computing). It calls for the database systems to support multiple models (e.g., relational model, graph model, tensor model) to support diversified applications (e.g., relational data analysis, graph computing and machine learning). We can embed AI algorithms into databases, design in-database machine learning framework, utilize database techniques to accelerate AI algorithms, and provide AI capability inside databases.

%They are not integrated. Databases are usually based on single data model and cannot support integrated data analysis (IDA). Because now most databases store data in well-defined schemas (static) and only support structured data analysis.  It's expensive to aggregate data from different databases.
%emails, text files, web pages, digital images, multimedia content, navigation details and social media posts.

(3) Transitional databases only consider general-purpose hardware, e.g., CPU, RAM and disk, but cannot make full use of new hardware, e.g., ARM, AI chips, GPU, FPGA, NVM, RDMA. It calls for a heterogeneous computing framework that can efficiently utilize diversified computing powers to support data management, data analysis, and in-database machine learning. 

% operations.


% AI-Naive: idea contributions		
To address these problems, we propose an AI-native database (\oursys), which not only integrates AI techniques into database to make database more intelligent but also provides in-database AI capabilities. In particular, on one hand, \oursys integrates AI techniques into databases to provide self-configuring, self-optimizing, self-healing, self-diagnosis, self-monitoring, self-security and self-assembling capabilities for databases, which can improve the database's availability, performance and stability, and reduce the burden of intensive human involvement. On the other hand, \oursys enables databases to provide AI capabilities using declarative languages, in order to lower the barrier of using AI. \oursys also fully utilizes diversified computing power to support data analysis and machine learning. 

An AI-native database can be divided into five stages. The first is AI-advised database, which takes an AI engine as a plug-in service and provides offline database suggestions, e.g., offline index advisor, offline knob tuning. The second stage is AI-assisted database, which takes an AI engine as a built-in service and provides online monitoring and suggestions, e.g., online index advisor, online statistics collection, and online diagnosis. The third is AI-enhanced database. One one hand, it provides AI based database components, e.g., learned index, learned optimizer, learned cost estimation, learned storage layout. On the other hand, it provides in-database AI algorithms and accelerators. The fourth is AI-assembled database, which provides multiple data models (e.g., relational model, graph model, tensor model) and fully utilizes the new hardware to support heterogeneous computing. It can provide multiple options for each component, e.g., learned optimizer, cost-based optimizer, and rule-based optimizer, and thus can automatically select the best component for different scenarios. The fifth is AI-designed database, which integrates AI into the life cycle of database design, development, evaluation, and maintenance, which provides the best performance for every scenario. 


In this paper, we first present the details of AI-native databases and then provide the research challenges and opportunities for designing an AI-native database. 

%outside database and provide we pack AI tools into the database to achieve auxiliary optimization. Second, we implant them into the DB kernel to improve efficiency. Third, we reshape DB kernel based on AI tech and provide unified engine to provide both DB and AI services. Fourth, we deploy heterogeneous computing architecture to better support operations of both DB and AI. Finally, we 


%We make the following contributions in this paper.

%\noindent (1) 

%We propose a practical way to achieve AI-native database in five stages (see Section~\ref{sec:work}).   

%\noindent (2) We propose an AI-advised database, which packs AI tools to provides auxiliary optimization (see Section~\ref{subsec: advised}). 

%\noindent (3) We propose an AI-Assisted database, which implants AI tools into DB kernel to provide runtime optimization (see Section~\ref{subsec: assisted}).

%\noindent (4) We propose an AI-Enhanced database, which incorporates AI tech into DB kernel and provides unified engine to provide DB and AI services (see Section~\ref{subsec: enhanced}).

%\noindent (5) We propose an AI-Assembled database, which provides heterogeneous computing architecture to enhance DB and AI services (see Section~\ref{subsec: assemble}).

%\noindent (6) We propose an AI-Designed database, which integrates AI theory into its life cycle to achieve a real AI-native database (see Section~\ref{subsec: designed}).

