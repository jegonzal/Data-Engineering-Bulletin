%\documentclass[11pt, dvipdfm]{article}
\documentclass[11pt]{article}
\usepackage{deauthor,times,graphicx}
%\usepackage[hidelinks]{hyperref}

\newcommand{\pierre}[1]{\textbf{Pierre:}#1}
\newcommand{\sh}[1]{\textbf{Shady:}#1}


\graphicspath{{authorname/}}

\title{Ethical Challenges in the Future of Work}
% \title{Data Bulletin - IC7 - 10-15 pages}
\author{Pierre Bourhis\\
CNRS at CRIStAL\\
\texttt{{\footnotesize pierrebourhis@univ-lille1.fr}}
\and
Gianluca Demartini \\
University of Queensland\\
\texttt{{\footnotesize demartini@acm.org}}
\and
Shady Elbassuoni\\
American University of  Beriut\\
\texttt{{\footnotesize se58@aub.edu.lb}}
\and
Emile Hoareau\\
University Grenoble Alpes\\
\texttt{{\footnotesize Emilie.Hoareau@grenoble-iae.fr}}
\and
H. Raghav Rao\\
The University of Texas at San Antonio\\
\texttt{{\footnotesize hr.rao@utsa.edu}}
}


\begin{document}

\maketitle

\begin{abstract}
The rise of self-employment empowered by platforms such as Amazon Mechanical Turk and Uber has drastically changed our perception of work. The possibility to link requesters and workers from all over the world in a scalable manner has resulted in advancements in the work world that would not have been possible otherwise. However, many ethical concerns related to fairness, transparency, and bias regarding these new forms of work have also been raised. In this paper, we present our vision on these ethical issues, how they can be combated in the future of work, and how this will impact the data management research community and future work platforms.
\end{abstract}

\section{Introduction}  
The rise of online piecework platforms such as Amazon Mechanical Turk\footnote{\url{https://www.mturk.com/}} and Uber\footnote{\url{https://www.uber.com/}} are profoundly changing the way we conduct work. These platforms typically link requesters to workers from all over the world in a scalable manner, providing the opportunity to  accomplish work in an unprecedented way. However, while these transformations offer numerous opportunities to both stakeholders, they also bring threats especially for workers, who are more vulnerable against requesters' demands and platforms' setups. The traditional work environment is highly regulated through law to avoid power imbalance and thus abuses from the more powerful actor, the employer, can be avoided. Online work platforms remain, at this time, less subject to strong regulations, which could then foster unfair situations. Several studies have already pointed out the potential drawbacks of the practices of online work platforms especially towards workers \cite{kittur2013future}. The different roles and activities offered by online work platforms (e.g., requesters, contract workers, micro-tasking, etc.) make  the creation of an ethical and fair work environment challenging. 
% \pierre{Another try:} Moreover the different roles that a platform play in the process increase their power and the ethical issues. 
Indeed, while the main role of a platform is to allocate workers to  available jobs, it also needs to ensure work payments  and the security of both requesters and workers. 

In the future, work facilitated by online platforms may become unfair or harmful in the absence of a strong and deep ethical reflection. An ethical approach in this context is defined as stakeholders in the ``loop of work'' doing the ``right things'' based upon rationally justifiable standards. It is important to ensure that any artifact in the loop should not be used in ways that can harm people, the environment, and society. As such, each artifact would have to follow certain legal, regulatory, and ethical frameworks. It is important to ask questions about the relationship between humans and computational entities in terms of what are the implications of replacing and supplementing humans with machines, and also try to foresee both utopian and dystopian future-of-work scenarios in order to be prepared for both an optimistic future as well as a pessimistic future. The role of work platform  in the relationship between the job providers and the workers has to be better defined and regulated as compared to the current situation. Indeed, platforms could play several roles: putting in relation requesters and workers, transferring payments between them, ensuring a virtual platform where to do work. These roles have to be defined precisely and need to follow relevant legal obligations. The notion of work contract in this context becomes complex and often not well defined, as it puts in relation three parties (i.e., job providers, workers, and platforms) and in different contexts (e.g., online and offline). Requesters, workers, and platforms can also be in different countries and the question of which work legislation should apply is complex.

In this paper, we point out that practices of online work platforms may raise ethical issues which must be handled to aspire for a sustainable Future of Work (FoW). We focus on issues related to privacy, accountability, fairness (with regard to compensation and job allocation for instance), transparency and explainability. We offer a detailed view of each of them, presenting existing research and suggestions about future directions.

We  first detail them, presenting how they appear today and how they are addressed by existing scientific literature. Then, we suggest a path forward, for each of them. We focus on ethics in this case, as it would apply to the stakeholders consisting of the “worker”, the “requester” and the “platform”. The rise of  online work platforms raises several  major ethical issues: 
(i) \textit{privacy/access control} - ensuring that the use of the personal data is not used for harmful purposes; 
loss of personal information can result in negative consequences which could have an effect on physical and mental health
and  hence access control becomes an important tool for the protection of privacy, (ii) \textit{accountability} - identification of outcomes and procedures and association with the appropriate entities, with the goal of not violating system or organizational policies and rules for compliance, (iii) \textit{fairness} - in terms of equity or equality of decision outcomes such as compensation to workers, (iv) \textit{transparency} of decision making processes including rejected job applications, decision on task assignment, and on reward allocation,  (v) and \textit{explainability} of processes involved. These last two  focus on the degree of justification and truthfulness regarding explanations and information provided in the process of work as well as the rewards and the assignments.

\section{Related Work}

Several researchers have started to explore online work platforms especially in the context of crowdsourcing. Crowdsourcing involves the distribution of tasks to various people, often across the world, via the Internet. The strength of crowdsourcing is that a variety of skills are instantly available and work can be conducted online in any language. From the point of view of these piecework workers, while some may be working at hours when they are not in their official work capacity, in order to make some extra money, for others, like Uber drivers, the work may actually be a full time job. In this section we review some of the related work regarding work condition and ethics of crowdsourcing.


Deng et al. \cite{deng2016duality} explore microtask crowdsourcing as perceived by crowd workers, revealing their values as a means of informing the design of such platforms. Analyzing detailed narratives of 210 crowd workers participating in Amazon's Mechanical Turk, they uncovered a set of nine values they share: access, autonomy, fairness, transparency, communication, security, accountability, making an impact, and dignity. They found that these values are implicated in four crowdsourcing structures: compensation, governance, technology, and microtask. Two contrasting perceptions—empowerment and marginalization—coexist, forming a duality of microtask crowdsourcing. Their study heightens awareness of worker marginalization in microtask crowdsourcing, and offers guidelines for improving crowdsourcing practice. Specifically, they offer recommendations regarding the ethical use of crowd workers (including for academic research), and call for improving platform design for greater worker empowerment.

Adda et al. \cite{adda2014crowdsourcing} discussed the issue of compensation (monetary or otherwise) for completed tasks on crowdsourcing platforms. They also discussed the ethical and legal issues raised when considering work on crowdsourcing platforms as labor in the legal sense. They used crowdsourcing
for under-resourced languages as a case study to exemplify
the different issues they discussed. Finally, they proposed some specific solutions for researchers who wish to use crowdsourcing in an ethical manner. 

Gellman \cite{gellman2015crowdsourcing} reviewed legal and regulatory issues that federal agencies face when
they engage in citizen science and crowdsourcing activities. His report identified relevant issues that most federal agencies must consider, reviewed the legal standards, suggested ways that agencies can comply with or lawfully evade requirements, and discussed practical approaches
that can ease the path for federal citizen science and crowdsourcing projects, including
procedural activities, cooperative actions, legislative changes, and regulatory adjustment.

Brey \cite{brey2000disclosive} provided a critique of mainstream computer ethics and argued for the importance of a complementary approach called \textit{disclosive} computer ethics, which is concerned with the moral deciphering of embedded values and norms in computer systems, applications and practices. Also, four key values were proposed as starting points for disclosive studies in computer ethics: justice, autonomy, democracy and privacy. Finally, it was argued that research in disclosive computer ethics should be multi-level and interdisciplinary, distinguishing between a disclosure level, a theoretical level, and an application level.

Schmidt \cite{schmidt2013good} discussed some of the ethical implications of crowdsourcing in general and of contest-based crowd design in particular, especially in regard to the question of fair payment. He established four different categories of crowdsourcing with separate ethical challenges and argues for the crowd work industry to develop a code of ethics from within, in order to counter the exploitation and abuse that it often enables.
% 
In \cite{dynamo} authors proposed and tested such a bottom-up approach to defining a code of practice for crowdsourcing platform use which resulted in a set of guidelines for requesters to provide fair work conditions to Mechanical Turk workers.

Williamson \cite{williamson2016ethics} examined the ethics of crowdsourcing in social science research, with reference to her own experience using Amazon’s Mechanical Turk. She pointed out that many people work long hours completing surveys and other tasks for very low wages, relying on those incomes to meet their basic needs. She resented her own experience of interviewing Mechanical Turk participants about their sources of income, and she offered recommendations to individual researchers, social science departments, and journal editors regarding the more ethical use of crowdsourcing.
% 
In \cite{earnings}, authors present a data-driven study of crowd worker wages showing how, on average, Mechanical Turk workers earn about \$2 per hour while only 4\% earns more than the US federal minimum wage.

Ford et al. \cite{ford2015crowdsourcing}  reviewed the various ways organizations employ non employees to overcome human resource limitations. They then focused on crowdsourcing as a novel source of external labor. After presenting key questions that every organization considering the use of crowdsourcing must address, they offered specific recommendations for those organizations who choose to employ a crowd to meet their needs. 

Saxton et al. \cite{saxton2013rules} provided a practical yet rigorous definition of crowdsourcing that incorporates crowds, outsourcing, and social web technologies. They then analyzed 103 well-known crowdsourcing websites using content analysis methods and the hermeneutic reading principle. Based on their analysis, they developed a ``taxonomic theory'' of crowdsourcing by organizing the empirical variants in nine distinct forms of crowdsourcing models. They also discussed key issues and directions, concentrating on the notion of managerial control systems.

Garber et al. \cite{graber2013internet} demonstrated that the crowdsourcing model of research has the potential to cause harm to participants, manipulates the participant into continued participation, and uses participants as experimental subjects. They concluded that protocols relying on this model require institutional review board (IRB) scrutiny.

Harris \cite{harris2011dirty} explored the potential for which crowdsourcing may be used to bypass commonly-established ethical standards for personal or professional gain. 
% 
Adda et al. \cite{adda2011crowdsourcing} demonstrated that the situation in crowdsourcing is far from being ideal, be it from the point of view of quality, price, workers’ status or ethics. Their goal was threefold: 1- to inform researchers, so that they can make their own choices with all the elements of such reflection in mind, 2- to ask for help from funding agencies and scientific associations, and develop alternatives, 3- to propose practical
and organizational solutions in order to improve new language resources development, while limiting the risks of ethical and legal issues without letting go of price or quality.

In this paper we present a summary of the current and envisioned future forms of work taking a stand on the ethical challenges that will need to be faced, including issues of transparency, fairness, and bias.

\section{Open Issues in Current Platform-based Work}
Empowering workers and protecting their rights and privacy should be at the heart of the Future of Work (FoW). This is a critical challenge as, while work platforms have a global reach, policies and regulations remain local for the most part. Advances in cybersecurity can be used to address privacy and access control mechanisms to guarantee that the right actors have visibility of the right data.
Platforms should provide different privacy settings and be transparent about what  data about workers is exposed and to whom. Requesters should be transparent about what the purpose of work is, and how the work  outcome will be utilized. They should also be able to protect their confidential information when needed and to protect the copyrights and intellectual property of the work done by workers. Fair compensation for workers, including base payments, bonuses, benefits and insurance should be guaranteed and regulated by law. 
Workers should have the freedom to choose the compensation type they deem acceptable. Finally, job allocation should be transparent, fair and explainable by design. Worker’s sensitive attributes that might bias the job allocation process should be protected. Auditing mechanisms to ensure compliance with fair, transparent and explainable job allocation and compensation need to be developed and adopted. Even though these ethical approaches are well known in the context of traditional work settings, these are more complex when applied through virtual platforms such as crowdsourcing. Workers are not considered as employees of the platforms but rather as self-employed workers that are paid for a one-off service. The question of which type of relation exists between workers and platforms is complex as different countries and states legislate differently on this issue. For example, California would consider drivers of Uber as employees. Platforms have also some other legal obligations such as the security of workers or requesters. For example, Uber has been banned from London because it was not able to guarantee the security of the drivers and customers. 


In terms of fairness, an interdisciplinary approach will be required to develop novel methods to assess and quantify algorithmic fairness in job allocation practices. For example, looking at bias trade-offs between fully-algorithmic vs human-in-the-loop job allocation methods where algorithmic bias could lead to different issues as compared to implicit bias in humans.
This will also result in higher levels of algorithmic transparency for job allocation where decisions should be easy to explain independently of whether they have been made by humans or by AI models.
Processes and procedures should be in place to specify how to best address unfair cases, e.g., by means of additional rewards for workers or novel/better job opportunities. We also envision novel methods to make job allocation distribution (i.e., the long tail effect where few workers complete most of the available jobs) and time spent on jobs more transparent to workers and external actors like compliance agents. For example, visual analytics dashboards that communicate to workers how much time they spent and how much money they have earned on a platform, with warnings on risks for addiction or on unfair payments, or how transparent the requesters are with regard to the rules and procedures regarding compensation, for instance, are important in the FoW space. The power of the platform to delete the account of a worker  or to prioritize particular workers over others  creates difference in the work relations among the platform. These decisions should not only be explained, but processes should be put in place for workers and work providers to contest these unilateral platform decisions.



To summarize, in most of online work platforms, workers are currently poorly protected from the pressure of platforms and work providers, thus creating a power imbalance that puts workers in an unfavourable condition with limited or no contractual power.  This situation raises a growing number of ethical issues related to privacy/access control, fairness and compensation. 

First, the level of privacy is currently quite low since workers do not have control over their own data and their final work output. As IP regulations are non clear or almost non-existent, transfer of property rights is currently in favour of requesters which use the results/outputs of the crowd as they wish. Moreover, data relating to workers (personal information and online behaviour, for instance) are under the complete control of the platform and of the requesters.


Second, workers’ compensation is limited. In some circumstances, workers are ready to work for free as they find some intrinsic motivation to do the job (pleasure to do a fun task, satisfaction to take part in a social/humanitarian/scientific project, willingness to be recognized by peers or the need to develop human and social capital). However, voluntary work also raises a number of issues: how to recruit enough volunteers? How to ensure work quality? How to mobilize them for a specific task within a specific time frame? 
% 
Most of the time, workers are compensated by means of task-based payments. Here also, a huge number of issues emerge regarding this compensation mechanism. Task-based payment often leads to very low income, which is typically under the official minimum wage of the worker’s country as the workers cannot negotiate their compensation. In addition, workers do not have the usual work benefits they would typically have in traditional work such as luncheon vouchers and health insurance, for instance. Finally, workers have no social security as they do not get paid if they are unable to work for any reasons (disease, lack of skills, less job offers, etc.). 

Third, job platform offer a great opportunity for people who cannot work in a physical workplace to work anyway online. However, it remains, at the same time, a place where discrimination is currently maintained and perpetuated. 


\section{Requirements for the Future of Work}
Workers’ \textbf{privacy} should be at the heart of the future of work. Platforms should provide different privacy options and be transparent about what worker data is exposed and to whom. Access control for requesters should also be supported, for instance by having workers sign non-disclosure agreements for sensitive work. Finally, requesters should be transparent about what the work is for, and how the work outcome will be utilized and who owns what. 

\textbf{Compensation} for workers should be fair and regulated by law. More training for workers should be provided, as this is mutually beneficial for workers and requesters and leads to a higher worker retention rate. Transparent work contracts  that clearly indicate conditions of work should also be available. Base payments and bonuses should be provided for paid work as well as work protection and insurance for volunteers. Workers should have the freedom to choose among different compensation types (either paid, free or platform credits, for instance).  

Finally, \textbf{job allocation} should be transparent and fair. Work platforms should explain to workers why or why not they have been allocated certain jobs. The job allocation algorithms should be open and explainable by design. Access control on sensitive attributes that might bias the job allocation process should be supported. Auditing mechanisms to ensure compliance with fair, transparent and explainable job allocation should be in place. Regulations to guarantee compliance with fairness requirements should be implemented. 

The Universal Declaration of Human Rights (UDHR) (www.un.org/en/universal-declaration-human-rights/) points to the inherent dignity of human beings as the foundation for freedom, justice and peace in the world. It would be important to revisit the UDHR to develop fundamental principles of consistent and fair crowdsourcing practices for the future. 

\section{Impact on Data Engineering Research}
\subsection{Research on Privacy and Access Control}
In terms of privacy and access control, required changes for FoW platforms will trigger advances in research on cybersecurity including topics on privacy management and access control. This will include designing novel and usable privacy control mechanisms for all involved actors where workers can decide how much information to disclose to the platforms at different points in time and for different jobs, requesters can have data confidentiality guarantees in place where confidential data and business processes can be safely managed even if exposed to external on-demand workers. For example, NDA workers will be trusted not to disclose confidential information they may encounter while completing jobs with well defined legal implications in case of non compliance.

Together with advances in the computational field, we envision a catch up of the regulatory framework around the future job market where international law research will need to deal with challenges of conflicting regulations across national boundaries for cases in which the different actors involved are covered by different legal systems.
From an ethical point of view, research practices will need to adapt to make sure experimenters disclose information to participating subjects on how they are being involved in an experiment and for which purpose their data is being used (e.g., informed consent). 

In terms of \textbf{compensation}, we envision a more structured approach where researchers will be required to follow standard guidelines on how to reward participating subjects. This may include standards for monetary rewards (e.g., official price list per task type) as well as standards on how to manage volunteer participation (e.g., researchers being required to follow up with participants to disseminate the results of their research conducted thanks to volunteer contributions).

\subsection{Research on Fairness}
Fairness is an ethical concept which is addressed by numerous fields and perspectives. Roughly defined, fairness is the idea that an individual should obtain what it deserves. In work platforms, the issue of fairness mainly concerns the compensation system and job allocation process.


In terms of fairness, an interdisciplinary approach will be required to develop novel methods to assess and quantify algorithmic fairness in job allocation practices. For example, looking at bias trade-offs between fully-algorithmic vs human-in-the-loop job allocation approaches where algorithmic bias could be different from implicit bias in humans. It would also be necessary to be cognizant of selection bias, where the data inputs to the algorithms are not representative of a population and could result in conclusions that would favor certain groups over others. Further, it would be necessary to look out for unintended promotion of biases where feedback loops perpetuate bias in results.  

% \subsection{Fairness of compensation}
By compensation, we refer to what is obtained by the worker in exchange for their work. In some cases, workers are willing to work without financial compensation in the extent that they find some intrinsic motivation to do the job, for instance, pleasure to do a funny task, satisfaction to take part to a social, humanitarian or scientific project, development of human and social capital. Most of the time, workers are compensated by a task-based payment, which raises a huge number of fairness concerns. One of the most prominent issue is the low income associated to task-based payments. As the workers cannot negotiate their compensation, they are often paid under the official minimum wage of their country. In addition, workers cannot benefit of usual advantages granted to traditional workers as health insurance, for example. Lastly, workers lacks of job security since if they are unable work for any reasons (illness, lack of skills, no job offer), they would not get paid. 

% \textit{Suggestion for the FoW.}
As the unfairness of compensation is the most visible abuse of current paid crowdsourcing, we advocate for the development of strong regulation through national and international law. From an ethical point of view, we propose to implement for each kind of task, a base payment estimated by automatic calculations or negotiated by stakeholders. This minimum payment could then be supplemented by bonuses based on work performance. In addition, we claim that the main compensation type (i.e. financial compensation) is severely limited as compared to the wide range of compensation types potentially adopted. We therefore suggest to extended the kind of compensation also including training, bonuses, credit for insurance or social protection, or any other convenience item on the platform. Workers could hence choose the kind of compensation they prefer in accordance with theses goals or actual situation. 
As far as voluntary work is concerned, we recommend the mandatory integration of an insurance scheme which could prevent the occurrence of mental health issues caused by the job (e.g., due to online content moderation tasks). 


\subsection{Research on Algorithmic Transparency}
This will also result in higher levels of algorithmic transparency for job allocation where job allocation decisions should be easy to explain independently of whether they have been made by humans, algorithms, or by a combination of those.
% 
The other side of the coin is to develop methods to assess algorithmic unfairness \cite{speicher2018unified}. While it may be easy for a human to determine what is fair or unfair based on fundamental ethical principles, understanding the level of fairness or unfairness is important in order to make decisions. Quite obviously there would be several situations where one would have to take the most fair or least unfair decision. 
This also calls for an additional research direction - \textbf{methods to fix unfair decisions}. In cases in which job allocation or compensation decisions have been judged to be unfair by a compliance verification step, processes should be in place to specify how to best address the situation, e.g., by means of additional rewards for workers or novel/better job opportunities.
% 
We also envision novel methods to make job allocation distribution (i.e., the long tail effect where few workers complete most of the available jobs) and time spent on jobs more transparent to workers and external actors like compliance agents. For example, visual analytics dashboards that communicate to workers how much time they spent and how much money they have earned on a platform with warnings on risks for addiction or unfair payments.

While, to-date, the literature has discussed the human-in-the-loop, soon, researchers will need to be studying society-in-the-loop (SITL) \cite{rahwan2018society} methods. Innovations need the wisdom of the crowd, in fact, the collaboration of the crowd with algorithms is expected to be the future \cite{malone2018human}. Rahwan \cite{rahwan2018society} points out that, to move from human-in-the-loop to SITL,  would be necessary in the case  to have mechanisms for negotiating the values of various stakeholders, bringing in the social contract. This results in a whole new level of complexity, since often, aspects of the social contract are implicit rather than explicit and are embedded in social norms bringing in issues of ethics. Further, there is the issue of how to resolve trade-offs between security and privacy, or various aspects of fairness while at the same time considering unbiased inputs to algorithms through algorithmic regulations. 


An interesting evolution in the context of FoW is the use of \textbf{smart contracts} which are developed to design and manage virtually contracts. They are used to establish contract between different participants and the rules of this contract are ensured by methods currently based on block chains. The ability to express a formal contract that could be transparent for the different participants and be ensured by some clear and automatic mechanisms would simply and clarify the interactions between workers and requesters. 


\section{Impact on Work Platforms}
As ethical issues of FoW lies heavily on governance mechanisms, work platform will be impacted at several levels. Depending on the evolution of law, platform transformations will be voluntary or mandatory. 

Ensuring privacy and increasing access control means providing all users (worker and requesters) with the ability to modulate their privacy parameters. They must be able to decide what kind of information can be disclosed and to whom. For instance, the user account may include a section called ``privacy parameters'' where users have access to  information related to them (personal information, work history, log files, performance measure, and so on) and for each users could switch a button to express their willingness to disclose it. Since users' behaviours are tracked and monitored, they need to know what kind of data is being collected, for what reasons, how is is treated, where it is stored and when it gets deleted. Regarding the platform, theses needs implies to provide users a space where they can get informed (e.g., a section in the user account). Information relating to the treatment of behaviour’s data could also be included in the general policy which should be read and accepted by any users. 

As fairness issues lie on the algorithms used by platforms to select workers, assign jobs, and evaluate outputs, platforms should be accountable for them. Many mechanisms to restrict the use of highly-unfair algorithms are available: disclosing them to the public, legal authorities or third parties, compliance to law, and frequent auditing.  Thanks to the future developments in algorithms auditing research \cite{auditing}, Fow should rely on sophisticated auditing techniques and tools.
Platform development would be impacted since they will have to be more rigorous when designing algorithms, integrating fairness while building algorithms, and accept frequent auditing processes. Depending on the development of law and scientific research on fairness measures and scales, compliance to standards may be formally required. 
Support to requesters and workers is another driver of fairness. Platforms are in the best position to do so. Today, some platforms already offer their support for designing tasks, defining the reward, and controlling quality. However, this service is rare and most of the time it does not consider fairness. In addition, platforms often take the requesters side in case of conflict with workers as they are seen as the customer. In the Fow, platforms should become more active and concerned about requesters needs as well as about the quality of requester-worker relationships. They can, for example, develop algorithms in order to model the utility function of the workers, be moderating and listening to both sides during conflict resolution, helping to fix performance criteria for requesters, and provide opportunities for improvement to workers. A greater monitoring of the platform activities may lead to avoiding mistakes, abuses, and unfair decisions.     

Fow platforms should integrate a sophisticated compensation system. First, the different kinds of compensation can be expanded to include training, bonuses, insurance, and others. Training appears as a compensation type that may be beneficial to all stakeholders: For the platform, it is a good way to obtain better crowd retention rates; requesters then would have access to highly skilled workers; and workers could earn better wages. 
% 
Insurance could prevent workers being harmed by the work itself, especially in the case of voluntary jobs. Taxes may be charged to platforms, in order to fund compliance activities and worker insurance. With this system, platforms could then offer the opportunity to workers to decide how they want to be compensated. To go further, they could design a recommendation system which does a matchmaking between work/workers/kind of compensations. At the second level, when focusing on the monetary compensation, FoW will include specific support mechanism for setting rewards  to prevent unfairness (e.g., checking the average wage balance across genders). Helping requesters to fix a reward  which matches  the difficulty and the length of the task would be a good way to ensure that workers will receive a decent payment. Guidelines for worker compensation can be also be made available by platforms. Ideally, fair Fow platform will deny jobs with a very low monetary compensation. However, as requesters are the main customers of these platforms, it is more realistic to envision a negotiation process unless strict regulations are put in place. 


As discussed in this study, FoW platforms have to face complex challenges as they are designed to serve different purposes: their main role is to match workers and requesters but they also provide payments to the workers, guarantee the security of workers and requesters, provide the technical support for running the tasks. If the matchmaking challenge has got a lot of attention by the research community, the other issues are often forgotten even though they have important ethical aspects. The current mix of the different roles in  work platforms creates high complexity in managing access control over the data as well as challenges related to  fairness and explainability. We believe that a clearer distinction of the different roles in platforms and possibly a better separation of them could lead to more ethical work processes.


% \section{Increasing Fairness of Compensation in FoW Platforms}
% The rise of  work platforms raises two major ethical issues: (i) privacy and (ii) fairness. 


% \textbf{(ii) Fairness}
% \underline{Definition of fairness}



% \subsection{Fairness of job allocation}
% % \underline{Definition}
% Job allocation is how each task is assigned to a specific worker. This process may be  partially or entirely automatic, supported by the algorithms running on the platform. Fairness issues in this context concerns the worker-job matchmaking algorithms, as they may include and perpetuate biases which could harm workers. 

% DUPLICATED TEXT
% \textit{Suggestion for the FoW.}
% Job allocation should be transparent and fair. Platforms should explain to workers why or why not they have been allocated certain jobs. The job allocation algorithms should be open and explainable by design. Access control on sensitive attributes that might bias the job allocation process should be supported. Auditing mechanisms to ensure compliance with fair, transparent and explainable job allocation should be in place. Regulations to guarantee compliance with fairness requirements should be implemented.  


% \section{The Platform responsibilities}


% More training for workers should be provided, which is mutually beneficial for the workers and the requesters and leads to a higher worker retention. 


% \textbf{(i) accountability} 

% \textbf{(ii) transparency} 

% Transparent work contracts should also be available and that clearly indicate conditions of work. 

% transparency of data treatment

% transparency of processes and algorithms systems

% \textbf{explainability}


% \section{Avenues of Research for Ethical FoW Platforms}
\section{Conclusions}
FoW will require overhauling the design and engineering of online job platforms to enable the collection, storage, retrieval, analysis, and mining of a wide array of human data across different types of technology-driven work. A fair bit of engineering and testing will be needed to ensure the development of scalable and portable platforms and the integration of multi-stakeholder goals in efficient and effective ways.

We call the data engineering community to consider working on the upcoming FoW research challenges as data will be the key enabler of the FoW. While doing this, we urge the community to also consider the ethical dimension of  innovative solutions to make sure that aspects of privacy, accountability, fairness, and transparency/explainability are embedded by design in such data-driven solutions for FoW platforms.

% DUPLICATED TEXT
% In terms of \textbf{privacy and access control}, required changes for FoW platforms will trigger advances in research on cybersecurity including topics on privacy management and access control. This will include designing novel and usable privacy control mechanisms for all involved actors where workers can decide how much information to disclose to the platforms at different points in time and for different jobs, requesters can have data confidentiality guarantees in place where confidential data and business processes can be safely managed even if exposed to external on-demand workers. For example, NDA workers will be trusted not to disclose confidential information they may encounter while completing jobs with well defined legal implications in case of non compliance.
% Together with advances in the computational field, we envision a catch up of the regulatory framework around the future job market where international law research will need to deal with challenges of conflicting regulations across national boundaries for cases in which the different actors involved are covered by different legal systems.
% From an ethical point of view, research practices will need to adapt to make sure experimenters disclose information to participating subjects on how they are being involved in an experiment and for which purpose their data is being used (e.g., informed consent).

% DUPLICATED TEXT
% In terms of \textbf{compensation}, we envision a more structured approach where researchers will be required to follow standard guidelines on how to reward participating subjects. This may include standards for monetary rewards (e.g., official price list per task type) as well as standards on how to manage volunteer participation (e.g., researchers being required to follow up with participants to disseminate the results of their research conducted thanks to volunteer contributions).

% DUPLICATED TEXT
% In terms of \textbf{fairness}, an interdisciplinary approach will be required to develop novel methods to assess and quantify algorithmic fairness in job allocation practices. For example, looking at bias trade-offs between fully-algorithmic vs human-in-the-loop job allocation approaches where algorithmic bias could be different from implicit bias in humans. This will also result in higher levels of algorithmic transparency for job allocation where job allocation decisions should be easy to explain independently of whether they have been made by humans, algorithms, or by a combination of those. 



% DUPLICATED TEXT
% We also envision novel methods to make job allocation distribution (i.e., the long tail effect where few workers complete most of the available jobs) and time spent on jobs more transparent to workers and external actors like compliance agents. For example, visual analytics dashboards that communicate to workers how much time they spent and how much money they have earned on a platform with warnings on risks for addiction or unfair payments.








%Malone, T. W. (2018). How human-computer’Superminds’ are redefining the future of work. MIT Sloan Management Review, 59(4), 34-41.

%Rahwan, I. Society-in-the-loop: programming the algorithmic social contract. Ethics Inf Technol (2018) 20: 5. https://doi.org/10.1007/s10676-017-9430-8

%Till Speicher, Hoda Heidari, Nina Grgic-Hlaca, Krishna P. Gummadi, Adish Singla, Adrian Weller, and Muhammad Bilal Zafar. 2018. A Unified Approach to Quantifying Algorithmic Unfairness: Measuring Individual &Group Unfairness via Inequality Indices. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD '18). ACM, New York, NY, USA, 2239-2248. DOI: https://doi.org/10.1145/3219819.3220046


% \begin{figure}

% \includegraphics[bb= xlow ylow xhigh yhigh]{figs/myfigure.png}

% \caption{A simple figure.}

% \end{figure}

\bibliographystyle{abbrv}
\begin{thebibliography}{10}
	
	\bibitem{adda2014crowdsourcing}
	G.~Adda, J.~Mariani, L.~Besacier, and H.~Gelas.
	\newblock {\em Crowdsourcing for Speech: Economic, Legal and Ethical analysis}.
	\newblock PhD thesis, LIG lab, 2014.
	
	\bibitem{adda2011crowdsourcing}
	G.~Adda, B.~Sagot, K.~Fort, and J.~Mariani.
	\newblock Crowdsourcing for language resource development: Critical analysis of
	amazon mechanical turk overpowering use.
	\newblock In {\em 5th Language and Technology Conference}, 2011.
	
	\bibitem{brey2000disclosive}
	P.~Brey.
	\newblock Disclosive computer ethics.
	\newblock {\em ACM Sigcas Computers and Society}, 30(4):10--16, 2000.
	
	\bibitem{deng2016duality}
	X.~Deng, K.~Joshi, and R.~D. Galliers.
	\newblock The duality of empowerment and marginalization in microtask
	crowdsourcing: Giving voice to the less powerful through value sensitive
	design.
	\newblock {\em Mis Quarterly}, 40(2):279--302, 2016.
	
	\bibitem{ford2015crowdsourcing}
	R.~C. Ford, B.~Richard, and M.~P. Ciuchta.
	\newblock Crowdsourcing: A new way of employing non-employees?
	\newblock {\em Business Horizons}, 58(4):377--388, 2015.
	
	\bibitem{gellman2015crowdsourcing}
	R.~Gellman.
	\newblock Crowdsourcing, citizen science, and the law: legal issues affecting
	federal agencies.
	\newblock {\em Commons Lab, Woodrow Wilson International Center for Scholars},
	2015.
	
	\bibitem{graber2013internet}
	M.~A. Graber and A.~Graber.
	\newblock Internet-based crowdsourcing and research ethics: the case for irb
	review.
	\newblock {\em Journal of medical ethics}, 39(2):115--118, 2013.
	
	\bibitem{earnings}
	K.~Hara, A.~Adams, K.~Milland, S.~Savage, C.~Callison-Burch, and J.~P. Bigham.
	\newblock A data-driven analysis of workers' earnings on amazon mechanical
	turk.
	\newblock In {\em Proceedings of the 2018 CHI Conference on Human Factors in
		Computing Systems}, page 449. ACM, 2018.
	
	\bibitem{harris2011dirty}
	C.~G. Harris.
	\newblock Dirty deeds done dirt cheap: a darker side to crowdsourcing.
	\newblock In {\em 2011 IEEE Third International Conference on Privacy,
		Security, Risk and Trust and 2011 IEEE Third International Conference on
		Social Computing}, pages 1314--1317. IEEE, 2011.
	
	\bibitem{kittur2013future}
	A.~Kittur, J.~V. Nickerson, M.~Bernstein, E.~Gerber, A.~Shaw, J.~Zimmerman,
	M.~Lease, and J.~Horton.
	\newblock The future of crowd work.
	\newblock In {\em Proceedings of the 2013 conference on Computer supported
		cooperative work}, pages 1301--1318. ACM, 2013.
	
	\bibitem{malone2018human}
	T.~W. Malone.
	\newblock How human-computer’superminds’ are redefining the future of work.
	\newblock {\em MIT Sloan Management Review}, 59(4):34--41, 2018.
	
	\bibitem{rahwan2018society}
	I.~Rahwan.
	\newblock Society-in-the-loop: programming the algorithmic social contract.
	\newblock {\em Ethics and Information Technology}, 20(1):5--14, 2018.
	
	\bibitem{dynamo}
	N.~Salehi, L.~C. Irani, M.~S. Bernstein, A.~Alkhatib, E.~Ogbe, K.~Milland,
	et~al.
	\newblock We are dynamo: Overcoming stalling and friction in collective action
	for crowd workers.
	\newblock In {\em Proceedings of the 33rd annual ACM conference on human
		factors in computing systems}, pages 1621--1630. ACM, 2015.
	
	\bibitem{auditing}
	C.~Sandvig, K.~Hamilton, K.~Karahalios, and C.~Langbort.
	\newblock Auditing algorithms: Research methods for detecting discrimination on
	internet platforms.
	\newblock {\em Data and discrimination: converting critical concerns into
		productive inquiry}, 22, 2014.
	
	\bibitem{saxton2013rules}
	G.~D. Saxton, O.~Oh, and R.~Kishore.
	\newblock Rules of crowdsourcing: Models, issues, and systems of control.
	\newblock {\em Information Systems Management}, 30(1):2--20, 2013.
	
	\bibitem{schmidt2013good}
	F.~A. Schmidt.
	\newblock The good, the bad and the ugly: Why crowdsourcing needs ethics.
	\newblock In {\em 2013 International Conference on Cloud and Green Computing},
	pages 531--535. IEEE, 2013.
	
	\bibitem{speicher2018unified}
	T.~Speicher, H.~Heidari, N.~Grgic-Hlaca, K.~P. Gummadi, A.~Singla, A.~Weller,
	and M.~B. Zafar.
	\newblock A unified approach to quantifying algorithmic unfairness: Measuring
	individual \&group unfairness via inequality indices.
	\newblock In {\em Proceedings of the 24th ACM SIGKDD International Conference
		on Knowledge Discovery \& Data Mining}, pages 2239--2248. ACM, 2018.
	
	\bibitem{williamson2016ethics}
	V.~Williamson.
	\newblock On the ethics of crowdsourced research.
	\newblock {\em PS: Political Science \& Politics}, 49(1):77--81, 2016.
	
\end{thebibliography}


%\begin{thebibliography}{10}
%\itemsep=1pt
%\begin{small}

%\bibitem{askit2012} R.~Boim, O.~Greenshpan, T.~Milo, S.~Novgorodov, N.~Polyzotis, and W.-C. Tan. \newblock Asking the right questions in crowd data sourcing. \newblock {\em ICDE}, 0:1261–1264, 2012.



%\end{small}
%\end{thebibliography}

\end{document}
