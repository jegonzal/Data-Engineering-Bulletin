\noindent \textbf{Database Tuner}. Database tuner is placed for maintaining the metadata. Considering the shortcomings of the traditional tuning technology~\cite{DBLP:journals/pvldb/DuanTB09, DBLP:conf/cloud/ZhuLGBMLSY17}, we use the machine-learning-based tuning component instead. Different from traditional rule-based programming~\cite{DBLP:conf/cloud/ZhuLGBMLSY17, DBLP:conf/fskd/WeiDH14}, mature machine learning technology learns the dependence between input and output from data (training samples), so that it can make more accurate prediction of unknown input. However, for database tuning, it is very difficult to obtain a large number of labeled data, because it is hard to find the optimal configuration under specific scenarios. So an appropriate learning model matters.

Traditional machine learning has strong generalization ability, which makes this kind of tuning model perform well in different database environments. In addition, it can effectively utilize the experience learned in historical tasks and apply it to future reference work. OtterTune~\cite{DBLP:conf/sigmod/AkenPGZ17} is a typical instance. However, this method also has many shortcomings. Firstly, this method adopts a pipeline architecture. The optimal solution obtained in the previous stage is not guaranteed to be the optimal solution in the next stage, and the models used in different stages may not be well matched. Secondly, it requires a large number of high-quality samples for training models, which are difficult to obtain. For example, database performance is affected by many factors such as disk capacity, CPU status, workload and so on. It is difficult to reproduce similar scenarios in large quantities. In addition, the regression model like Gauss Process is relatively simple. And it is difficult to optimize the database tuning problem with high-dimensional continuous space.

Therefore, we choose DRL technology as the tuning model~\cite{DBLP:conf/sigmod/cdbtune19}. With efficient training algorithm, DRL can greatly improve the efficiency of tuning. Firstly, DRL does not need a lot of labeled data to train the network. Because under one workload, multiple training samples can be generated iteratively. Secondly, combining MDP, Bellman and gradient descent, the network can quickly fit the target. 

\noindent \textbf{Cardinality Estimator}. Cardinality estimator is placed in the query optimizer. As an important part of traditional database query optimization, cardinality estimation has been studied for decades, but the most advanced cardinality estimator in production environment still has great errors. Errors can even reach several orders of magnitude. In the case of such large cardinality estimation error, the query optimizer can not accurately estimate the execution cost, so that the constructed execution plan can not achieve good performance. According to Leis and Gubichev et al~\cite{DBLP:journals/pvldb/LeisGMBK015}, they test on real data sets, the challenge of cost estimation comes more from the accuracy of cardinality estimation.

Traditional statistical cardinality estimators works bad with big data. Sampling-based methods have the problem of sampling attenuation when estimating multi-table queries, while index-based sampling technology strongly depends on index structure. Recent work shows that~\cite{DBLP:conf/cidr/KipfKRLBK19, DBLP:conf/sigmod/OrtizBGK18}, machine learning can be used to achieve efficient, accurate and reliable cardinality estimation method. 
The cardinality estimation using machine learning algorithm can be roughly divided into two categories, 
one is to model only by query statement itself. The feature of this method is only extracted from the query statement itself, and it does not need the cardinality estimator to access the data table, nor does it need to know the specific execution of the query.
The other is query optimization process oriented modeling. This is a query optimizer-oriented approach that supports the estimation of each sub-query plan to help the optimizer make decisions. In addition, it can also realize direct cost intelligent learning without the participation of cost model, so that the link of adjusting parameters of cost model can be taken out for the system environment, so that the estimated cost is more robust in a specific environment, and the model also has the ability of automatic migration of multiple environments.

So we adopt the latter method to implement cardinality estimator. But traditional linear machine learning algorithms have many shortcomings, including inadequate abstraction ability of high-dimensional data. So we focus on building an efficient, robust and available cost estimator for query optimization. Firstly, feature engineering is applied to query execution plan, including how to code predicate expressions and node operations. Secondly, we use reinforcement learning model to obtain a general state representation by learning the representation of each multi-table connected subtree. Finally, we use convolutional neural network (CNN) to estimate the base values of queries corresponding to each general state.

\noindent \textbf{Query Planner}. Query planner is also placed in the query optimizer. The query planner has always been an important research issue in the field of database~\cite{DBLP:conf/sigmod/SelingerACLP79}. 
For a query statement, the query planner generates the corresponding join plan. Different join schemes have a great impact on query efficiency. Finding the best plan is a NP-hard problem. 
The traditional static algorithms depend on the performance of the cost estimator. However, the plan with the least cost given by the estimator is not necessarily the plan with the least running time in the real running process. Therefore, the performance of the static algorithm is limited by the effect of the estimator. 
And the artificially defined estimator is difficult to cover all cases and make accurate estimates.

We still choose to propose to use reinforcement learning in query planner.
We can use all join conditions as action space. The state space consists of all the join trees (Join Trees) in the execution of Join. The cost of each step is rewarded. Data management system is an interactive environment. Our goal is to find a proper strategy function, that is, how to take action in each state. Since, for each step, we use the cost of one-step join as the reward, the long-term reward corresponds to the future cost of the unfinished part. Once our strategy function can minimize long-term rewards, we can get the least-cost join plan according to the strategy function. In this problem, we take the running time of the system as the index, and the query planner based on reinforcement learning can continuously take the running time as feedback, so the performance of the plan is no longer limited by the performance of the cost estimator.

However, the traditional reinforcement learning method has some limits~\cite{DBLP:journals/access/MaglogiannisNSM18}. For example, Q-learning needs to use a table Q-table to record all states. The size of this table is very large, and Q-learning cannot handle the state that hasn't appeared very well. In order to solve this problem, recent work has proposed deep reinforcement learning (DRL) based approaches, such as DQ [76] and ReJOIN [75]. Different from the traditional reinforcement learning method, the deep reinforcement learning method uses the neural network to express the relations between the state and action of the problem. For example, in DQN, its core idea is to cancel Q-table and replace it with a network Q-network. For a state s, the previous approach was to search the state s in Q-table, and now use Q-network to calculate Q-network (s). At the same time, for a feedback from the executor, state s and its long-term reward Q are denoted as (S, Q). We use Q as the goal of s in Q-network to learn about the network. In order to enable the network to compute the state s, we need to first represent the state s as a vector, such as using a single heat vector, 1 and 0 to represent whether each point in Join Tree is in the tree, and for each column, using its selectivity as the feature of the column, so as to construct the representation vector of the state (Join Tree). Thanks to the powerful learning ability and generalization ability of the neural network, it can record the Q value it has learned, and give a good prediction for the next state s'.

\noindent \textbf{Index Builder}. Index builder is placed in the query executor. Indexing plays an important role in improving the efficiency of retrieval tasks on big data sets. Therefore, effective indexing technology is needed to support database operation. 

Traditional indexing methods, such as bitmap indexing and tree-based indexing, fails to fully meet needs of big data~\cite{DBLP:journals/kais/GaniSSH16}. Firstly, they can not effectively detect "unknown" user behavior, especially with large data. The commonly used indexes in DBMS are all general data structures. They do not analyze and utilize the distribution of data, nor do they make use of the more popular and common models in the real world. Secondly, the growth of data sets will also lead to the growth of index size.

Through machine learning, we can learn a model that reflects data patterns, and can automatically synthesize a special index structure at a lower cost, called \texttt{learning index}. Learning index can greatly reduce the spatial cost of index and significantly improve query performance. Based on Kraska's work~\cite{DBLP:conf/sigmod/KraskaBCDP18}, we use learning models to enhance or replace traditional index structures.

(1) \texttt{Range Index}. Range index can be regarded as a model that maps the lookup key to the location of the record in an ordered set. 
Firstly, the model for predicting the location of keys in a given sorted array is effectively similar to the cumulative distribution function (CDF), so a recursive model index (RMI) can be established.
Secondly, one of the biggest challenges in replacing B-trees with learning models is the "last mile search", for example, it is often difficult to reduce the prediction error rate from 100 M to hundreds of orders of magnitude using a single model. However, it is much simpler to reduce the error rate from 100M to 10K. Therefore, we can use a hierarchical model. At each stage, the model takes the key as input and selects another model based on it. Until the final stage, the output of the model is the record position. In this way, similar to B-tree nodes, each model is responsible for a certain area of the key space to make better prediction with a lower error rate.
Furthermore, the recursive model can also be used to mix different learning models according to the needs. For example, the top model can choose ReLU to learn a wider range of data distribution, while the bottom model uses linear regression model with less time and space costs.

(2) \texttt{Point Index}. For hash mapping index, the key problem is to avoid conflicts as much as possible. Conflicts will have a serious impact on performance or storage requirements. Machine learning model may provide alternatives to reduce the number of conflicts. Based on Hash model index, we also use the structure of recursive model, but how to deal with insertion, lookup and conflict depends on the hash mapping architecture. And we also try to learn better hash functions with CDF.

(3) \texttt{Bloom filter}. Based on Kraska et al, we introduce two ideas of building Bloom filter by machine learning methods. 
The first method is to take index as a binary probability Classification task, that is, to learn a model f, which can predict whether query x is a key or a non-key. The probability that the output of the model is a key is X. Then, if a threshold is chosen, the output is greater than x, then the model can be transformed into an existing index. 
The second method is to learn a hash function so that the hash function minimizes the conflicts between keys and non-keys.

\noindent \textbf{View Advisor}. View advisor is placed in the database engine. With the increasing scale of data, traditional databases faces the problem of inefficient batch execution of query statements. Experiments~\cite{DBLP:journals/pvldb/JindalKRP18, DBLP:conf/sigmod/JindalQPYDBFLKR18} show that there are many duplicate sub-queries in a batch. How to reduce the duplicate computation of sub-queries is becoming more and more important in the field of query optimization.

With the development of deep learning and reinforcement learning, more and more intelligent optimization technologies are used in the field of database. 
Massive historical query data makes it possible to build materialized views intelligently. 
Firstly, from the perspective of supervised learning, we can construct labeled data including queries, databases and views. That is, input includes queries, candidate views and database status. Label is whether each candidate view is selected. 
Secondly, from the perspective of unsupervised learning, we can use reinforcement learning to generate the optimal solution of materialized view selection interactively. Specifically, historical data can only provide empirical information, and only by combining the feedback of current queries can we better select the optimal materialized view. 
We can use different network structures to extract feature information for different data forms, such as RNN (Recurrent Neural Network) model for the sequence characteristics of query statements, and MLP (Multilayer Perceptron) model for database status information. Then, we can build Markov Decision Process (MDP) to model the selection of materialized views as an iterative optimization problem, and then use the existing deep reinforcement learning method to solve it.
